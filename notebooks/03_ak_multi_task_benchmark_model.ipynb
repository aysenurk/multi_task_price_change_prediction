{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.metrics import F1\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 3\n",
    "N_CURRENCIES = 3\n",
    "INPUT_FEATURE_SIZE = 3\n",
    "WINDOW_SIZE = 50\n",
    "TRAIN_PERCENTAGE, VAL_PERCENTAGE, TEST_PERCENTAGE = 0.70, 0.15, 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_series = \n",
    "# veri bu şekilde hazırlanmalı\n",
    "# data[N_CURRENCIES][SERIES_LEN][INPUT_FEATURE_SIZE]\n",
    "# input feature larından 0 price prediction için olan veriyi vermeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.23088973, 0.49757251, 0.34794033],\n",
       "        [0.57180844, 0.23812744, 0.07794263],\n",
       "        [0.29838999, 0.63729098, 0.31115375],\n",
       "        ...,\n",
       "        [0.0194084 , 0.00602222, 0.42604163],\n",
       "        [0.25265734, 0.97484391, 0.62643969],\n",
       "        [0.77926653, 0.81545885, 0.3772543 ]],\n",
       "\n",
       "       [[0.91432109, 0.7649435 , 0.97877158],\n",
       "        [0.5261074 , 0.1097452 , 0.57684679],\n",
       "        [0.88210343, 0.2215405 , 0.51642907],\n",
       "        ...,\n",
       "        [0.341817  , 0.78906859, 0.47354565],\n",
       "        [0.28950253, 0.36693896, 0.39319208],\n",
       "        [0.21129712, 0.79835578, 0.56124629]],\n",
       "\n",
       "       [[0.8169917 , 0.57190898, 0.70315261],\n",
       "        [0.295609  , 0.22288916, 0.658404  ],\n",
       "        [0.59673753, 0.00171058, 0.98495485],\n",
       "        ...,\n",
       "        [0.33328285, 0.27431204, 0.44759833],\n",
       "        [0.75785471, 0.11827018, 0.40642197],\n",
       "        [0.78897326, 0.26690853, 0.18392046]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_length = 2000\n",
    "sample_data = np.random.rand(N_CURRENCIES, series_length, INPUT_FEATURE_SIZE)\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 x: np.ndarray, \n",
    "                 data_use_type,\n",
    "                 train_percentage = TRAIN_PERCENTAGE,\n",
    "                 val_percentage = VAL_PERCENTAGE,\n",
    "                 test_percentage = TEST_PERCENTAGE,\n",
    "                 seq_len = WINDOW_SIZE, \n",
    "                 ):\n",
    "        \n",
    "        self.x = torch.tensor(x).float()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.data_use_type = data_use_type\n",
    "        \n",
    "        self.train_size = int(len(self.x[0]) * train_percentage)\n",
    "        self.val_size = int(len(self.x[0]) * val_percentage)\n",
    "        self.test_size = int(len(self.x[0]) * test_percentage)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        if self.data_use_type == \"train\":\n",
    "            return self.train_size - ( self.seq_len)\n",
    "        \n",
    "        if self.data_use_type == \"val\":\n",
    "            return self.val_size\n",
    "        \n",
    "        else:\n",
    "            return self.test_size\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        item = dict()\n",
    "        \n",
    "        if self.data_use_type ==\"val\":\n",
    "            index = self.train_size + index - self.seq_len\n",
    "            \n",
    "        elif self.data_use_type ==\"test\":\n",
    "            index = self.train_size + self.val_size + index - self.seq_len\n",
    "        \n",
    "        for i in range(N_CURRENCIES):\n",
    "                item[\"currency_\" + str(i) + \"_window\"] = self.x[i][index:index+self.seq_len]\n",
    "\n",
    "                price_change = self.x[i][index+self.seq_len][0] - self.x[i][index+self.seq_len-1][0]\n",
    "                item[\"currency_\" + str(i) + \"_label\"] = 0 if price_change == 0 else 1 if price_change >0 else 2 #2 düşüş\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'currency_0_window': tensor([[1.7442e-01, 9.0479e-01, 1.2487e-02],\n",
       "         [3.5751e-01, 4.6581e-01, 9.6337e-01],\n",
       "         [1.6700e-01, 5.4848e-02, 2.7434e-01],\n",
       "         [4.5875e-03, 1.1440e-01, 8.9658e-01],\n",
       "         [1.4810e-01, 4.0284e-01, 6.2324e-01],\n",
       "         [6.6001e-01, 2.8892e-01, 1.3432e-01],\n",
       "         [4.5089e-01, 6.6433e-01, 9.4611e-01],\n",
       "         [2.2359e-02, 7.6274e-01, 5.1573e-01],\n",
       "         [3.3987e-01, 6.6808e-01, 4.7247e-01],\n",
       "         [2.3938e-01, 4.0257e-01, 2.6294e-01],\n",
       "         [6.1641e-01, 7.6957e-02, 2.8933e-01],\n",
       "         [2.1328e-01, 6.4844e-01, 2.6555e-01],\n",
       "         [4.8892e-02, 4.2401e-01, 6.5794e-01],\n",
       "         [9.6582e-01, 5.2987e-01, 7.1647e-01],\n",
       "         [6.5245e-01, 2.4914e-01, 3.8616e-01],\n",
       "         [6.7862e-01, 8.7440e-01, 9.9986e-01],\n",
       "         [5.9575e-01, 1.6961e-01, 7.7485e-01],\n",
       "         [1.4100e-01, 9.3246e-01, 4.2034e-01],\n",
       "         [5.4767e-01, 1.1359e-01, 5.1333e-01],\n",
       "         [3.3162e-01, 1.8582e-01, 5.7527e-01],\n",
       "         [8.0051e-01, 9.2673e-01, 5.0295e-01],\n",
       "         [4.3504e-01, 1.5587e-01, 4.6556e-02],\n",
       "         [5.7949e-01, 4.6930e-01, 1.6865e-01],\n",
       "         [5.6010e-01, 6.8143e-01, 8.7506e-01],\n",
       "         [4.9934e-01, 9.1214e-01, 4.1040e-01],\n",
       "         [3.2326e-02, 4.0792e-01, 5.8306e-01],\n",
       "         [8.6226e-02, 6.8108e-01, 5.2119e-01],\n",
       "         [9.4732e-01, 4.2835e-01, 6.1925e-02],\n",
       "         [7.3100e-01, 7.7425e-01, 7.0510e-01],\n",
       "         [2.8604e-01, 7.6044e-04, 1.9011e-01],\n",
       "         [9.0733e-01, 9.5780e-01, 5.0324e-01],\n",
       "         [4.2714e-02, 2.9088e-01, 2.6691e-01],\n",
       "         [9.6922e-01, 2.8091e-01, 6.4993e-01],\n",
       "         [3.7538e-01, 9.6711e-01, 8.5476e-01],\n",
       "         [9.0669e-01, 2.2807e-01, 6.0265e-01],\n",
       "         [8.0773e-01, 3.9182e-01, 7.1253e-01],\n",
       "         [5.1617e-01, 8.8600e-01, 7.3146e-01],\n",
       "         [2.8296e-02, 2.1800e-01, 8.6952e-01],\n",
       "         [3.1856e-01, 2.4253e-01, 9.2815e-01],\n",
       "         [4.6267e-01, 3.2959e-01, 7.0497e-02],\n",
       "         [3.5453e-01, 2.4349e-01, 9.9245e-01],\n",
       "         [6.1356e-01, 1.8372e-01, 3.1724e-01],\n",
       "         [9.5760e-02, 2.7487e-01, 8.2005e-03],\n",
       "         [9.5786e-01, 2.9202e-01, 1.4375e-01],\n",
       "         [4.0124e-01, 8.5955e-01, 6.6131e-01],\n",
       "         [6.8735e-01, 8.3200e-01, 9.1477e-01],\n",
       "         [3.3834e-01, 3.8411e-01, 3.5817e-01],\n",
       "         [5.4073e-01, 5.3369e-01, 6.2758e-01],\n",
       "         [2.9456e-01, 8.4818e-01, 8.9066e-01],\n",
       "         [5.7578e-02, 1.8602e-01, 2.4809e-01]]),\n",
       " 'currency_0_label': 1,\n",
       " 'currency_1_window': tensor([[0.0673, 0.8211, 0.4059],\n",
       "         [0.6190, 0.5244, 0.1682],\n",
       "         [0.0672, 0.7819, 0.1607],\n",
       "         [0.2508, 0.3548, 0.3947],\n",
       "         [0.0889, 0.5287, 0.6553],\n",
       "         [0.8879, 0.9831, 0.1968],\n",
       "         [0.7814, 0.3355, 0.2070],\n",
       "         [0.4938, 0.3070, 0.8465],\n",
       "         [0.3547, 0.2833, 0.1569],\n",
       "         [0.4443, 0.0774, 0.8587],\n",
       "         [0.3852, 0.4706, 0.8229],\n",
       "         [0.9530, 0.9646, 0.2675],\n",
       "         [0.5190, 0.5300, 0.9945],\n",
       "         [0.4286, 0.0328, 0.1584],\n",
       "         [0.8398, 0.2941, 0.5622],\n",
       "         [0.1646, 0.5864, 0.7711],\n",
       "         [0.4416, 0.6591, 0.6168],\n",
       "         [0.0401, 0.2588, 0.7968],\n",
       "         [0.0337, 0.0411, 0.2269],\n",
       "         [0.3220, 0.9471, 0.6838],\n",
       "         [0.1624, 0.9572, 0.7289],\n",
       "         [0.2471, 0.8251, 0.5951],\n",
       "         [0.8087, 0.1992, 0.2452],\n",
       "         [0.3620, 0.6942, 0.1090],\n",
       "         [0.7039, 0.4955, 0.4754],\n",
       "         [0.8130, 0.1641, 0.3816],\n",
       "         [0.9974, 0.6949, 0.0993],\n",
       "         [0.1352, 0.6011, 0.1519],\n",
       "         [0.8452, 0.8237, 0.0011],\n",
       "         [0.3942, 0.1610, 0.9205],\n",
       "         [0.8790, 0.8709, 0.0727],\n",
       "         [0.7560, 0.8457, 0.2916],\n",
       "         [0.3652, 0.5008, 0.1261],\n",
       "         [0.0948, 0.9776, 0.1370],\n",
       "         [0.0374, 0.8585, 0.3462],\n",
       "         [0.2858, 0.3462, 0.7785],\n",
       "         [0.2827, 0.4824, 0.3161],\n",
       "         [0.9054, 0.5695, 0.6450],\n",
       "         [0.1310, 0.1166, 0.3283],\n",
       "         [0.2278, 0.4221, 0.4496],\n",
       "         [0.1602, 0.5390, 0.8875],\n",
       "         [0.0448, 0.9740, 0.7882],\n",
       "         [0.9523, 0.9354, 0.4168],\n",
       "         [0.5237, 0.9594, 0.8588],\n",
       "         [0.6159, 0.2610, 0.4911],\n",
       "         [0.7179, 0.5580, 0.7880],\n",
       "         [0.8984, 0.2455, 0.3677],\n",
       "         [0.8984, 0.2852, 0.1981],\n",
       "         [0.5467, 0.3734, 0.6341],\n",
       "         [0.9886, 0.1706, 0.4825]]),\n",
       " 'currency_1_label': 2,\n",
       " 'currency_2_window': tensor([[0.2256, 0.4177, 0.2309],\n",
       "         [0.9080, 0.4090, 0.0606],\n",
       "         [0.8481, 0.1855, 0.9388],\n",
       "         [0.8221, 0.4403, 0.0054],\n",
       "         [0.9105, 0.7134, 0.0694],\n",
       "         [0.5165, 0.3645, 0.3600],\n",
       "         [0.6810, 0.9151, 0.5219],\n",
       "         [0.4681, 0.8097, 0.1800],\n",
       "         [0.8749, 0.5565, 0.9409],\n",
       "         [0.4888, 0.7500, 0.0777],\n",
       "         [0.3794, 0.4083, 0.4551],\n",
       "         [0.6827, 0.8429, 0.9966],\n",
       "         [0.4636, 0.6019, 0.7215],\n",
       "         [0.2226, 0.8553, 0.7799],\n",
       "         [0.5030, 0.0192, 0.3373],\n",
       "         [0.5266, 0.3810, 0.8533],\n",
       "         [0.5145, 0.6630, 0.9092],\n",
       "         [0.9855, 0.2269, 0.9161],\n",
       "         [0.0237, 0.5566, 0.0312],\n",
       "         [0.1587, 0.6844, 0.8372],\n",
       "         [0.6670, 0.8759, 0.8226],\n",
       "         [0.3960, 0.3466, 0.4825],\n",
       "         [0.5724, 0.3651, 0.2722],\n",
       "         [0.6287, 0.7262, 0.1193],\n",
       "         [0.7045, 0.7006, 0.7673],\n",
       "         [0.6535, 0.0241, 0.6718],\n",
       "         [0.3152, 0.8871, 0.8544],\n",
       "         [0.7739, 0.8879, 0.7938],\n",
       "         [0.8507, 0.2781, 0.3714],\n",
       "         [0.1529, 0.6622, 0.7222],\n",
       "         [0.3518, 0.3957, 0.0161],\n",
       "         [0.6632, 0.8771, 0.4895],\n",
       "         [0.0681, 0.7482, 0.9901],\n",
       "         [0.0617, 0.1071, 0.8565],\n",
       "         [0.0523, 0.9116, 0.0977],\n",
       "         [0.3651, 0.7310, 0.4949],\n",
       "         [0.0682, 0.7599, 0.2455],\n",
       "         [0.6896, 0.5294, 0.5928],\n",
       "         [0.5548, 0.8172, 0.7816],\n",
       "         [0.7778, 0.2810, 0.1498],\n",
       "         [0.5661, 0.4436, 0.8134],\n",
       "         [0.3110, 0.4276, 0.9921],\n",
       "         [0.4361, 0.3693, 0.9773],\n",
       "         [0.4676, 0.3957, 0.5583],\n",
       "         [0.8887, 0.1950, 0.0235],\n",
       "         [0.4846, 0.8413, 0.9055],\n",
       "         [0.0673, 0.6875, 0.3379],\n",
       "         [0.1009, 0.4365, 0.9626],\n",
       "         [0.7422, 0.9416, 0.6991],\n",
       "         [0.1503, 0.5535, 0.0598]]),\n",
       " 'currency_2_label': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiTimeSeriesDataset(sample_data, \"test\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "deneme = torch.tensor(0.0, device=\"cuda:0\", requires_grad=True) + torch.tensor(0.0, device=\"cuda:0\", requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "deneme += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series = sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_based__multi_task_classification_model(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 data = time_series,\n",
    "                 num_classes = N_CLASSES,\n",
    "                 input_size = INPUT_FEATURE_SIZE,\n",
    "                 batch_size= 8,\n",
    "                 lstm_hidden_size = 256,\n",
    "                 lstm_stack_size = 3,\n",
    "                 lstm_dropout = 0.5,\n",
    "                 bidirectional = False,\n",
    "                 ):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.data = time_series\n",
    "        self.num_classes = num_classes\n",
    "        self.input_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.lstm_hidden_size = lstm_hidden_size\n",
    "        self.lstm_stack_size = lstm_stack_size\n",
    "        self.lstm_dropout = lstm_dropout\n",
    "        self.bidirectional = bidirectional \n",
    "        \n",
    "        self.stack_lstm = nn.LSTM(input_size = self.input_size, \n",
    "                hidden_size = self.lstm_hidden_size, \n",
    "                num_layers= self.lstm_stack_size,\n",
    "                dropout = self.lstm_dropout,\n",
    "                bidirectional = self.bidirectional, \n",
    "                batch_first=True,)\n",
    "        \n",
    "#         self.linear1 = nn.Linear(self.lstm_hidden_size, 128)\n",
    "        \n",
    "#         self.linear2 = nn.Linear(128, 64)\n",
    "        \n",
    "#         self.activation = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(64, self.num_classes)\n",
    "        \n",
    "        self.f1_score = pl.metrics.F1(num_classes=self.num_classes)\n",
    "        self.accuracy_score = pl.metrics.Accuracy()\n",
    "        \n",
    "        self.train_dl = DataLoader(MultiTimeSeriesDataset(self.data, \"train\"), \n",
    "                                   batch_size=self.batch_size)\n",
    "        \n",
    "        self.val_dl = DataLoader(MultiTimeSeriesDataset(self.data, \"val\"),\n",
    "                                 batch_size=self.batch_size)\n",
    "        \n",
    "        self.test_dl = DataLoader(MultiTimeSeriesDataset(self.data, \"test\"), \n",
    "                                  batch_size=self.batch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(x.size()[0], x.size()[1], self.input_size) #(batch, window_len, feature_size)\n",
    "        \n",
    "        x, _=  self.stack_lstm(x)\n",
    "        x = x[:, -1, :] # equivalent to return sequence = False on keras :)\n",
    "        \n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        x = self.linear2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        output = self.output_layer(x)\n",
    "        #print(\"output1\", output[0])\n",
    "        #output = F.log_softmax(x, dim = 1)\n",
    "        output = F.softmax(output)\n",
    "        #print (\"output\", output.size())\n",
    "        return output\n",
    "    \n",
    "    def training_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = F.nll_loss(output, y)\n",
    "        self.log('train_loss', loss, on_step=True, prog_bar=True)\n",
    "        \n",
    "        acc = self.accuracy_score(torch.max(output, dim=1)[1], y)\n",
    "        self.log('train_acc', acc, on_step=True, prog_bar=True)\n",
    "        \n",
    "        f1 = self.f1_score(torch.max(output, dim=1)[1], y)\n",
    "        self.log('train_f1', f1, on_step=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = F.nll_loss(x, y)\n",
    "        self.log('val_loss', loss, on_epoch=True, reduce_fx=torch.mean, prog_bar=True)\n",
    "        \n",
    "        #print(torch.max(output, dim=1)[1])\n",
    "        acc = self.accuracy_score(torch.max(output, dim=1)[1], y)\n",
    "        self.log('val_acc', acc, on_epoch=True, reduce_fx=torch.mean, prog_bar=True)\n",
    "        \n",
    "        f1 = self.f1_score(torch.max(output, dim=1)[1], y)\n",
    "        self.log('val_f1', f1, on_epoch=True, reduce_fx=torch.mean, prog_bar=True)\n",
    "        \n",
    "    def test_step(self, batch, batch_nb):\n",
    "        x, y = batch\n",
    "        output = self(x)\n",
    "        loss = F.nll_loss(x, y)\n",
    "        self.log('test_loss', loss, on_epoch=True, reduce_fx=torch.mean)\n",
    "        \n",
    "        acc = self.accuracy_score(torch.max(output, dim=1)[1], y)\n",
    "        self.log('test_acc', acc, on_epoch=True, reduce_fx=torch.mean)\n",
    "        \n",
    "        f1 = self.f1_score(torch.max(output, dim=1)[1], y)\n",
    "        self.log('test_f1', f1, on_epoch=True, reduce_fx=torch.mean)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=6e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.7)\n",
    "        #weight and biases\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return self.train_dl\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.val_dl\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./lightning_logs/version_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(name='lstm.v1',project='pytorchlightning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_based_classification_model()\n",
    "trainer = pl.Trainer(gpus=-1, \n",
    "                     logger = wandb_logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maysenurk\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.28<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">lstm.v1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/aysenurk/pytorchlightning\" target=\"_blank\">https://wandb.ai/aysenurk/pytorchlightning</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/aysenurk/pytorchlightning/runs/2r146yth\" target=\"_blank\">https://wandb.ai/aysenurk/pytorchlightning/runs/2r146yth</a><br/>\n",
       "                Run data is saved locally in <code>/home/aysenurk/Projects/OzU/CS_540_MLF/multi_task_price_change_prediction/notebooks/wandb/run-20210430_182716-2r146yth</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type     | Params\n",
      "--------------------------------------------\n",
      "0 | stack_lstm     | LSTM     | 1.3 M \n",
      "1 | linear1        | Linear   | 32.9 K\n",
      "2 | linear2        | Linear   | 8.3 K \n",
      "3 | activation     | ReLU     | 0     \n",
      "4 | output_layer   | Linear   | 195   \n",
      "5 | f1_score       | F1       | 0     \n",
      "6 | accuracy_score | Accuracy | 0     \n",
      "--------------------------------------------\n",
      "1.4 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.4 M     Total params\n",
      "5.437     Total estimated model params size (MB)\n",
      "/home/aysenurk/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, val dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validation sanity check'), FloatProgress(value=1.0, bar_style='info', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-68e6531421ec>:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(output)\n",
      "/home/aysenurk/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30f5dc841204032a0be13245d5dd88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Validating'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aysenurk/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/aysenurk/anaconda3/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, test dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438817eda72746b5a4f6f62d8d8af9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Testing'), FloatProgress(value=1.0, bar_style='info', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-68e6531421ec>:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = F.softmax(output)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': 0.5954198241233826,\n",
      " 'test_f1': 0.5954198241233826,\n",
      " 'test_loss': -28952.98828125}\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': -28952.98828125,\n",
       "  'test_acc': 0.5954198241233826,\n",
       "  'test_f1': 0.5954198241233826}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropout, batch normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f46e05073d0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3_multi_task_price_change_prediction",
   "language": "python",
   "name": "py3_multi_task_price_change_prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from src.TimeSeriesLearningUtils import TimeSeriesDataset\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(currency_list,\n",
    "             data_frequency,\n",
    "             pred_frequency, \n",
    "             num_classes,\n",
    "             window_size,\n",
    "             neutral_quantile = 0.33,\n",
    "             beg_date = pd.Timestamp(2017,1,1),\n",
    "             end_date = pd.Timestamp.now(),\n",
    "             log_price = True,\n",
    "             remove_trend = False,\n",
    "             decompose = False,\n",
    "             ma_period = 0,\n",
    "             indicators = False,\n",
    "             imfs = False,\n",
    "             ohlv = False,\n",
    "              **kwargs):\n",
    "\n",
    "        X, y, dfs = {}, {}, {}     \n",
    "        \n",
    "        for cur in currency_list:\n",
    "            df = pd.read_csv(f\"../data/0_raw/Binance/{str.lower(cur)}_usdt_{data_frequency}.csv\", header=None,index_col=0)\n",
    "            df.index = pd.to_datetime(df.index, unit='ms')\n",
    "            df.sort_index(inplace=True)\n",
    "            df.columns = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "            \n",
    "            if indicators:\n",
    "                from ta import add_all_ta_features\n",
    "                indicators_df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\n",
    "                df[indicators_df.columns] = indicators_df\n",
    "          \n",
    "            if imfs:\n",
    "                from PyEMD import EEMD\n",
    "                eemd = EEMD(parallel=True, processes=2)\n",
    "                imfs_result = eemd(df[\"close\"].values, max_imf=7)\n",
    "                imf_features = [\"imf_\"+str(i) for i in range(imfs_result.shape[0])]\n",
    "                df = pd.concat((df, pd.DataFrame(imfs_result.T, columns=imf_features, index=df.index)), axis=1)\n",
    "            \n",
    "            if log_price:\n",
    "                df[[\"close\", \"open\", \"high\", \"low\"]] = df[[\"close\", \"open\", \"high\", \"low\"]].apply(np.log, axis=1)\n",
    "                   \n",
    "            if num_classes == 3:\n",
    "                pct_diff = df['close'].pct_change()\n",
    "                quantile_value = pct_diff.abs().quantile(neutral_quantile).loc[neutral_quantile]\n",
    "                \n",
    "                conditions = [(pct_diff < 0) & (pct_diff.abs() > quantile_value),\n",
    "                              (pct_diff > 0) & (pct_diff.abs() > quantile_value)]\n",
    "\n",
    "                classes = [0,1] # 2 is the default class if none of conditions is met, i.e. price change in the neutral range\n",
    "            \n",
    "                change_dir = np.select(conditions, classes, default=2)\n",
    "            \n",
    "            else: \n",
    "                change_dir = df['close'].diff().apply(lambda x: 0 if x <= 0 else 1)\n",
    "            \n",
    "            df.insert(loc=0, column=\"change_dir\", value=change_dir)   \n",
    "            \n",
    "            if remove_trend:\n",
    "                #from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "                #ma_period = ma_period if pred_frequency in ['d', 'D'] else ma_period * 4\n",
    "                #components = seasonal_decompose(df[\"close\"], model=\"additive\", period = ma_period, two_sided=False)\n",
    "                #df[\"close\"] -= components.trend\n",
    "                df['diff'] = df['close'].diff()\n",
    "                #df['diff'] = df['close'].pct_change()\n",
    "                df.drop('close', axis=1, inplace=True)\n",
    "                df.dropna(inplace=True) \n",
    "\n",
    "            if decompose: \n",
    "                from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "                ma_period = ma_period if pred_frequency in ['d', 'D'] else ma_period * 4 #if pred_frequency is 6h, then multiply the ma_period by 4 \n",
    "                components = seasonal_decompose(df[\"close\"], model=\"additive\", period = ma_period, two_sided=False)\n",
    "                df['trend'] = components.trend\n",
    "                df['residual'] = components.resid  \n",
    "                df['seasonal'] = components.seasonal\n",
    "                df.dropna(inplace=True)  \n",
    "\n",
    "            if not ohlv: #keeping open, high, low, and volume\n",
    "                df.drop([\"open\", \"high\", \"low\", \"volume\"], axis=1, inplace=True)\n",
    "\n",
    "            dfs[cur] = df\n",
    "        \n",
    "        min_dates = [df.index.min() for cur, df in dfs.items()]\n",
    "        max_dates = [df.index.max() for cur, df in dfs.items()]\n",
    "        beg_date = max([max(min_dates), beg_date])\n",
    "        end_date = min([min(max_dates), end_date])\n",
    "        common_range = pd.date_range(beg_date, end_date, freq=pred_frequency)\n",
    "        \n",
    "        missing = set()\n",
    "        common_set = set(common_range)\n",
    "        for cur, df in dfs.items():\n",
    "            missing_steps = common_set.difference(df.index)\n",
    "            missing |= missing_steps\n",
    "        common_range = common_range.drop(missing)\n",
    "        \n",
    "        X = np.array([dfs[cur].loc[common_range].drop([\"change_dir\"], axis=1).values for cur in currency_list])\n",
    "        y = np.array([dfs[cur].loc[common_range, \"change_dir\"].values for cur in currency_list])\n",
    "        features = df.columns.tolist()\n",
    "        features.remove(\"change_dir\")\n",
    "\n",
    "        return X, y, features, dfs, common_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data2(currency_list,\n",
    "             data_frequency,\n",
    "             pred_frequency, \n",
    "             num_classes,\n",
    "             window_size,\n",
    "             neutral_quantile = 0.33,\n",
    "             beg_date = pd.Timestamp(2017,1,1),\n",
    "             end_date = pd.Timestamp.now(),\n",
    "             log_price = True,\n",
    "             remove_trend = False,\n",
    "             ma_period = 0,\n",
    "             include_indicators = False,\n",
    "             include_imfs = False,\n",
    "             ohlv = False,\n",
    "             drop_missing = True,\n",
    "              **kwargs):\n",
    "\n",
    "        X, y, dfs = {}, {}, {}     \n",
    "        \n",
    "        for cur in currency_list:\n",
    "            df = pd.read_csv(f\"../data/0_raw/Binance/{str.lower(cur)}_usdt_{data_frequency}.csv\", header=None,index_col=0)\n",
    "            df.index = pd.to_datetime(df.index, unit='ms')\n",
    "            df.sort_index(inplace=True)\n",
    "            df.columns = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "            \n",
    "            if include_indicators:\n",
    "                from ta import add_all_ta_features\n",
    "                indicators_df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\n",
    "                df[indicators_df.columns] = indicators_df\n",
    "            \n",
    "            if include_imfs:\n",
    "                from PyEMD import EEMD\n",
    "                eemd = EEMD(parallel=True, processes=2)\n",
    "                imfs = eemd(df[\"close\"].values, max_imf=7)\n",
    "                imf_features = [\"imf_\"+str(i) for i in range(imfs.shape[0])]\n",
    "                df = pd.concat((df, pd.DataFrame(imfs.T, columns=imf_features, index=df.index)), axis=1)\n",
    "            \n",
    "            if log_price:\n",
    "                df[[\"close\", \"open\", \"high\", \"low\"]] = df[[\"close\", \"open\", \"high\", \"low\"]].apply(np.log, axis=1)\n",
    "                   \n",
    "            if num_classes == 3:\n",
    "                df['pct_diff'] = df['close'].pct_change()\n",
    "                neutral_quantiles = df['pct_diff'].abs().quantile(neutral_quantile).loc[neutral_quantile]\n",
    "\n",
    "                conditions = [(df['pct_diff'] < 0) & (df['pct_diff'].abs() > neutral_quantiles),\n",
    "                              (df['pct_diff'] > 0) & (df['pct_diff'].abs() > neutral_quantiles)]\n",
    "\n",
    "                classes = [0,1] # 2 is the default class if none of conditions is met, i.e. price change in the neutral range\n",
    "            \n",
    "                change_dir = np.select(conditions, classes, default=2)\n",
    "            \n",
    "            else:\n",
    "                df['diff'] = df['close'].diff()\n",
    "                change_dir = df['diff'].apply(lambda x: 0 if x <= 0 else 1)\n",
    "            \n",
    "            df.insert(loc=0, column=\"change_dir\", value=change_dir)   \n",
    "            df.dropna(inplace=True)  \n",
    "            \n",
    "            if remove_trend:\n",
    "                from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "                components = seasonal_decompose(df[\"close\"].values, period=3, model=\"additive\")#, period = ma_period, two_sided=False)\n",
    "                df[\"close\"] -= components.trend\n",
    "                df.dropna(inplace=True)\n",
    "                \n",
    "            if not ohlv: #keeping open, high, low, and volume\n",
    "                df.drop([\"open\", \"high\", \"low\", \"volume\"], axis=1, inplace=True)\n",
    "\n",
    "            dfs[cur] = df\n",
    "        \n",
    "        min_dates = [df.index.min() for cur, df in dfs.items()]\n",
    "        max_dates = [df.index.max() for cur, df in dfs.items()]\n",
    "        beg_date = max([max(min_dates), beg_date])\n",
    "        end_date = min([min(max_dates), end_date])\n",
    "        common_range = pd.date_range(beg_date, end_date, freq=pred_frequency)\n",
    "        \n",
    "        missing = set()\n",
    "        common_set = set(common_range)\n",
    "        for cur, df in dfs.items():\n",
    "            missing_steps = common_set.difference(df.index)\n",
    "            missing |= missing_steps\n",
    "        common_range = common_range.drop(missing)\n",
    "        \n",
    "        diff_col = 'pct_diff' if num_classes == 3 else 'diff'\n",
    "\n",
    "        X = np.array([dfs[cur].loc[common_range].drop([\"change_dir\", diff_col], axis=1).values for cur in currency_list])\n",
    "        y = np.array([dfs[cur].loc[common_range, \"change_dir\"].values for cur in currency_list])\n",
    "        features = df.columns.tolist()\n",
    "        features.remove(\"change_dir\")\n",
    "        \n",
    "        return X, y, features, dfs, common_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_LST = ['BTC', 'ETH', 'LTC', 'XRP', 'ADA']\n",
    "num_classes = 2\n",
    "FREQUENCY = \"d\"\n",
    "WINDOW_SIZE = 400\n",
    "NEUTRAL_QUANTILE = 0.33,\n",
    "dataset_percentages = [0.90, 0.05, 0.05]\n",
    "train_pct = 0.8\n",
    "LOOK_AHEAD = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features, dfs, common_range = get_data(currency_list= CURRENCY_LST,\n",
    "                               data_frequency='1d',\n",
    "                               pred_frequency=FREQUENCY,\n",
    "                               num_classes = num_classes, \n",
    "                               window_size = WINDOW_SIZE,\n",
    "                               neutral_quantile = NEUTRAL_QUANTILE,\n",
    "                               log_price = True,\n",
    "                               remove_trend = True,\n",
    "                               ma_period = 7,\n",
    "                               indicators = False,\n",
    "                               imfs = False,\n",
    "                               decompose = False,\n",
    "                               ohlv = False,\n",
    "                               beg_date = pd.Timestamp(2017,1,1),\n",
    "                               end_date = pd.Timestamp(2022,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1197, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.530822</td>\n",
       "      <td>0.001648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499220</td>\n",
       "      <td>0.043587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.502607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        change_dir         diff\n",
       "count  1460.000000  1460.000000\n",
       "mean      0.530822     0.001648\n",
       "std       0.499220     0.043587\n",
       "min       0.000000    -0.502607\n",
       "25%       0.000000    -0.015750\n",
       "50%       1.000000     0.001810\n",
       "75%       1.000000     0.019939\n",
       "max       1.000000     0.202952"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfs['BTC']\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC\n",
      "0.9984152139461173\n",
      "0.8501805054151624\n",
      "ETH\n",
      "1.0\n",
      "0.8483754512635379\n",
      "LTC\n",
      "0.9857369255150554\n",
      "0.8537906137184116\n",
      "XRP\n",
      "0.9667194928684627\n",
      "0.8393501805054152\n",
      "ADA\n",
      "0.9841521394611727\n",
      "0.8375451263537906\n"
     ]
    }
   ],
   "source": [
    "LOOK_AHEAD=6\n",
    "data = {}\n",
    "for i, cur in enumerate(CURRENCY_LST):\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\n",
    "    \n",
    "    train_size = int(len(seq_X) * train_pct)\n",
    "    test_size = len(seq_X) - train_size\n",
    "\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\n",
    "    X_train = seq_X[:train_size]\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\n",
    "    y_test = y[i][train_size:]\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train[:-LOOK_AHEAD], y_train[LOOK_AHEAD:])\n",
    "    print(cur)\n",
    "    #print(lr.coef_)\n",
    "    print(lr.score(X_train[:-LOOK_AHEAD], y_train[LOOK_AHEAD:]))\n",
    "    print(lr.score(X_test[:-LOOK_AHEAD], y_test[LOOK_AHEAD:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC\n",
      "0.9937205651491365\n",
      "0.8678571428571429\n",
      "ETH\n",
      "1.0\n",
      "0.8517857142857143\n",
      "LTC\n",
      "0.9858712715855573\n",
      "0.8553571428571428\n",
      "XRP\n",
      "0.9811616954474097\n",
      "0.85\n",
      "ADA\n",
      "0.9968602825745683\n",
      "0.8589285714285714\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for i, cur in enumerate(CURRENCY_LST):\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\n",
    "\n",
    "    train_size = int(len(seq_X) * train_pct)\n",
    "    test_size = len(seq_X) - train_size\n",
    "\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\n",
    "    X_train = seq_X[:train_size]\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\n",
    "    y_test = y[i][train_size:]\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(cur)\n",
    "    #print(lr.coef_)\n",
    "    print(lr.score(X_train, y_train))\n",
    "    print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC\n",
      "1.0\n",
      "0.8714285714285714\n",
      "ETH\n",
      "1.0\n",
      "0.8607142857142858\n",
      "LTC\n",
      "1.0\n",
      "0.8571428571428571\n",
      "XRP\n",
      "1.0\n",
      "0.8642857142857143\n",
      "ADA\n",
      "1.0\n",
      "0.8696428571428572\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for i, cur in enumerate(CURRENCY_LST):\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\n",
    "    \n",
    "    train_size = int(len(seq_X) * train_pct)\n",
    "    test_size = len(seq_X) - train_size\n",
    "\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\n",
    "    X_train = seq_X[:train_size]\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\n",
    "    y_test = y[i][train_size:]\n",
    "    rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(cur)\n",
    "    print(rf.score(X_train, y_train))\n",
    "    print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(rf.feature_importances_).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC\n",
      "1.0\n",
      "0.8660714285714286\n",
      "ETH\n",
      "1.0\n",
      "0.8517857142857143\n",
      "LTC\n",
      "1.0\n",
      "0.8446428571428571\n",
      "XRP\n",
      "1.0\n",
      "0.8660714285714286\n",
      "ADA\n",
      "1.0\n",
      "0.8553571428571428\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for i, cur in enumerate(CURRENCY_LST):\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\n",
    "    \n",
    "    train_size = int(len(seq_X) * train_pct)\n",
    "    test_size = len(seq_X) - train_size\n",
    "\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\n",
    "    X_train = seq_X[:train_size]\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\n",
    "    y_test = y[i][train_size:]\n",
    "    xgb = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', n_jobs=-1)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    print(cur)\n",
    "    print(xgb.score(X_train, y_train))\n",
    "    print(xgb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18 in c:\\users\\furkan\\appdata\\roaming\\python\\python38\\site-packages (1.18.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy==1.18 --user #required if keras produces an error related to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "43/43 - 8s - loss: 0.6946 - acc: 0.4862 - val_loss: 0.6944 - val_acc: 0.4853\n",
      "Epoch 2/30\n",
      "43/43 - 1s - loss: 0.6924 - acc: 0.4993 - val_loss: 0.6954 - val_acc: 0.4669\n",
      "Epoch 3/30\n",
      "43/43 - 1s - loss: 0.6902 - acc: 0.5371 - val_loss: 740462.1875 - val_acc: 0.5110\n",
      "Epoch 4/30\n",
      "43/43 - 1s - loss: 9852734.0000 - acc: 0.5240 - val_loss: 0.6964 - val_acc: 0.4412\n",
      "Epoch 5/30\n",
      "43/43 - 1s - loss: 0.6902 - acc: 0.5269 - val_loss: 0.6952 - val_acc: 0.4706\n",
      "Epoch 6/30\n",
      "43/43 - 1s - loss: 0.6900 - acc: 0.5153 - val_loss: 0.6967 - val_acc: 0.4522\n",
      "Epoch 7/30\n",
      "43/43 - 1s - loss: 0.6899 - acc: 0.5211 - val_loss: 0.6956 - val_acc: 0.4449\n",
      "Epoch 8/30\n",
      "43/43 - 1s - loss: 0.6898 - acc: 0.5124 - val_loss: 0.6954 - val_acc: 0.4449\n",
      "Epoch 9/30\n",
      "43/43 - 1s - loss: 0.6902 - acc: 0.5357 - val_loss: 0.6953 - val_acc: 0.4449\n",
      "Epoch 10/30\n",
      "43/43 - 1s - loss: 0.6896 - acc: 0.5342 - val_loss: 0.6947 - val_acc: 0.4412\n",
      "Epoch 11/30\n",
      "43/43 - 1s - loss: 0.6895 - acc: 0.5080 - val_loss: 0.6949 - val_acc: 0.4449\n",
      "Epoch 12/30\n",
      "43/43 - 1s - loss: 0.6895 - acc: 0.5284 - val_loss: 0.6954 - val_acc: 0.4449\n",
      "Epoch 13/30\n",
      "43/43 - 1s - loss: 0.6895 - acc: 0.5167 - val_loss: 0.6945 - val_acc: 0.4485\n",
      "Epoch 14/30\n",
      "43/43 - 1s - loss: 0.6897 - acc: 0.5298 - val_loss: 0.6940 - val_acc: 0.4853\n",
      "Epoch 15/30\n",
      "43/43 - 1s - loss: 0.6890 - acc: 0.5211 - val_loss: 0.6968 - val_acc: 0.4779\n",
      "Epoch 16/30\n",
      "43/43 - 1s - loss: 0.6891 - acc: 0.5357 - val_loss: 0.6951 - val_acc: 0.4559\n",
      "Epoch 17/30\n",
      "43/43 - 2s - loss: 0.6889 - acc: 0.5182 - val_loss: 0.6945 - val_acc: 0.4559\n",
      "Epoch 18/30\n",
      "43/43 - 2s - loss: 0.6890 - acc: 0.5328 - val_loss: 0.6957 - val_acc: 0.4632\n",
      "Epoch 19/30\n",
      "43/43 - 1s - loss: 0.6888 - acc: 0.5429 - val_loss: 0.6956 - val_acc: 0.4632\n",
      "Epoch 20/30\n",
      "43/43 - 1s - loss: 0.6883 - acc: 0.5153 - val_loss: 0.6945 - val_acc: 0.4743\n",
      "Epoch 21/30\n",
      "43/43 - 1s - loss: 0.6883 - acc: 0.5604 - val_loss: 0.6935 - val_acc: 0.4853\n",
      "Epoch 22/30\n",
      "43/43 - 1s - loss: 0.6876 - acc: 0.5575 - val_loss: 0.6952 - val_acc: 0.4743\n",
      "Epoch 23/30\n",
      "43/43 - 1s - loss: 0.6883 - acc: 0.5211 - val_loss: 0.6932 - val_acc: 0.4853\n",
      "Epoch 24/30\n",
      "43/43 - 1s - loss: 0.6876 - acc: 0.5575 - val_loss: 0.6943 - val_acc: 0.4853\n",
      "Epoch 25/30\n",
      "43/43 - 1s - loss: 0.6875 - acc: 0.5357 - val_loss: 0.6926 - val_acc: 0.5184\n",
      "Epoch 26/30\n",
      "43/43 - 1s - loss: 0.6871 - acc: 0.5429 - val_loss: 0.6910 - val_acc: 0.5368\n",
      "Epoch 27/30\n",
      "43/43 - 1s - loss: 0.6859 - acc: 0.5546 - val_loss: 1965766528.0000 - val_acc: 0.4926\n",
      "Epoch 28/30\n",
      "43/43 - 1s - loss: 16450657.0000 - acc: 0.5284 - val_loss: 0.7156 - val_acc: 0.4596\n",
      "Epoch 29/30\n",
      "43/43 - 1s - loss: 0.6900 - acc: 0.5357 - val_loss: 0.7007 - val_acc: 0.4853\n",
      "Epoch 30/30\n",
      "43/43 - 1s - loss: 0.6884 - acc: 0.5182 - val_loss: 0.6982 - val_acc: 0.5110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x259b5456c70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(WINDOW_SIZE, 1))))\n",
    "#model.add(Bidirectional(LSTM(100, activation='relu', input_shape=(200,WINDOW_SIZE, 1))))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# fit model\n",
    "model.fit(X_train.reshape(X_train.shape[0],-1,1), \n",
    "          y_train, \n",
    "          epochs=30, \n",
    "          batch_size=batch_size, \n",
    "          verbose=2,\n",
    "         validation_data=(X_test.reshape(X_test.shape[0],-1,1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 100, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(X_train.shape[0],-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "80/80 - 16s - loss: 0.8228 - acc: 0.4961 - val_loss: 0.4990 - val_acc: 0.7875\n",
      "Epoch 2/20\n",
      "80/80 - 0s - loss: 0.3849 - acc: 0.8823 - val_loss: 0.3970 - val_acc: 0.8571\n",
      "Epoch 3/20\n",
      "80/80 - 0s - loss: 0.2322 - acc: 0.9733 - val_loss: 0.3609 - val_acc: 0.8679\n",
      "Epoch 4/20\n",
      "80/80 - 0s - loss: 0.1385 - acc: 0.9953 - val_loss: 0.3517 - val_acc: 0.8732\n",
      "Epoch 5/20\n",
      "80/80 - 0s - loss: 0.0850 - acc: 1.0000 - val_loss: 0.3514 - val_acc: 0.8768\n",
      "Epoch 6/20\n",
      "80/80 - 0s - loss: 0.0540 - acc: 1.0000 - val_loss: 0.3614 - val_acc: 0.8821\n",
      "Epoch 7/20\n",
      "80/80 - 0s - loss: 0.0370 - acc: 1.0000 - val_loss: 0.3706 - val_acc: 0.8821\n",
      "Epoch 8/20\n",
      "80/80 - 0s - loss: 0.0268 - acc: 1.0000 - val_loss: 0.3830 - val_acc: 0.8839\n",
      "Epoch 9/20\n",
      "80/80 - 0s - loss: 0.0203 - acc: 1.0000 - val_loss: 0.3953 - val_acc: 0.8839\n",
      "Epoch 10/20\n",
      "80/80 - 0s - loss: 0.0157 - acc: 1.0000 - val_loss: 0.4073 - val_acc: 0.8839\n",
      "Epoch 11/20\n",
      "80/80 - 0s - loss: 0.0126 - acc: 1.0000 - val_loss: 0.4188 - val_acc: 0.8839\n",
      "Epoch 12/20\n",
      "80/80 - 0s - loss: 0.0103 - acc: 1.0000 - val_loss: 0.4288 - val_acc: 0.8839\n",
      "Epoch 13/20\n",
      "80/80 - 0s - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4401 - val_acc: 0.8804\n",
      "Epoch 14/20\n",
      "80/80 - 0s - loss: 0.0072 - acc: 1.0000 - val_loss: 0.4493 - val_acc: 0.8804\n",
      "Epoch 15/20\n",
      "80/80 - 0s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4585 - val_acc: 0.8786\n",
      "Epoch 16/20\n",
      "80/80 - 0s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4682 - val_acc: 0.8786\n",
      "Epoch 17/20\n",
      "80/80 - 0s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.4758 - val_acc: 0.8786\n",
      "Epoch 18/20\n",
      "80/80 - 0s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.4848 - val_acc: 0.8786\n",
      "Epoch 19/20\n",
      "80/80 - 0s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.4931 - val_acc: 0.8786\n",
      "Epoch 20/20\n",
      "80/80 - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5005 - val_acc: 0.8786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1247f3e0d60>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=batch_size, verbose=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 200, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(X_train.shape[0],-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 100, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(X_train, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>close</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.024659</td>\n",
       "      <td>-0.017351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.024570</td>\n",
       "      <td>0.005958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.013072</td>\n",
       "      <td>0.018154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027246</td>\n",
       "      <td>0.047933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>-0.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.013172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.019464</td>\n",
       "      <td>-0.006344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.014760</td>\n",
       "      <td>0.017635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.007075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            change_dir     close      diff\n",
       "0                                         \n",
       "2017-08-21           0 -0.024659 -0.017351\n",
       "2017-08-22           1 -0.024570  0.005958\n",
       "2017-08-23           1 -0.013072  0.018154\n",
       "2017-08-24           1  0.027246  0.047933\n",
       "2017-08-25           0  0.006414 -0.008219\n",
       "2017-08-26           1  0.001431  0.013172\n",
       "2017-08-27           0 -0.019464 -0.006344\n",
       "2017-08-28           1 -0.014760  0.017635\n",
       "2017-08-29           1  0.012603  0.044756\n",
       "2017-08-30           0  0.001160 -0.007075"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs2['BTC'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.017351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.018154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.047933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-09</th>\n",
       "      <td>1</td>\n",
       "      <td>0.054630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-10</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.014556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-11</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-12</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.024737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.073809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1454 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            change_dir      diff\n",
       "0                               \n",
       "2017-08-21           0 -0.017351\n",
       "2017-08-22           1  0.005958\n",
       "2017-08-23           1  0.018154\n",
       "2017-08-24           1  0.047933\n",
       "2017-08-25           0 -0.008219\n",
       "...                ...       ...\n",
       "2021-08-09           1  0.054630\n",
       "2021-08-10           0 -0.014556\n",
       "2021-08-11           0 -0.001624\n",
       "2021-08-12           0 -0.024737\n",
       "2021-08-13           1  0.073809\n",
       "\n",
       "[1454 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['BTC'].loc[dfs2['BTC'].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 1197, 5), (5, 1197))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 x: np.ndarray, \n",
    "                 y: np.ndarray,\n",
    "                 data_use_type,\n",
    "                 currency_list,\n",
    "                 dataset_percentages,\n",
    "                 window_size, \n",
    "                 **kwargs\n",
    "                 ):\n",
    "        self.currencies = currency_list\n",
    "        self.n_currencies = len(self.currencies)\n",
    "        self.x = torch.tensor(x[:self.n_currencies]).float()\n",
    "        self.y = torch.tensor(y[:self.n_currencies]).long()\n",
    "        self.seq_len = window_size\n",
    "        self.data_use_type = data_use_type\n",
    "        \n",
    "        train_percentage,val_percentage,test_percentage = dataset_percentages\n",
    "        self.train_size = int(len(self.x[0]) * train_percentage)\n",
    "        self.val_size = int(len(self.x[0]) * val_percentage)\n",
    "        self.test_size = len(self.x[0]) - self.train_size - self.val_size\n",
    "        \n",
    "        self.train_mean = [self.x[i][:self.train_size].mean(axis=0) for i in range(self.n_currencies)]\n",
    "        self.train_std = [self.x[i][:self.train_size].std(axis=0) for i in range(self.n_currencies)]\n",
    "        \n",
    "        #self.train_mean = self.x[:self.train_size].mean()\n",
    "        #self.train_std = self.x[:self.train_size].std()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        if self.data_use_type == \"train\":\n",
    "            return self.train_size - ( self.seq_len)\n",
    "\n",
    "        elif self.data_use_type == \"val\":\n",
    "            return self.val_size \n",
    "        else:\n",
    "            return self.test_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        item = dict()\n",
    "        \n",
    "        if self.data_use_type ==\"val\":\n",
    "            index = self.train_size + index - self.seq_len\n",
    "            \n",
    "        elif self.data_use_type ==\"test\":\n",
    "            index = self.train_size + self.val_size + index - self.seq_len\n",
    "        \n",
    "        for i in range(self.n_currencies):\n",
    "            window = self.x[i][index:index+self.seq_len]\n",
    "            #window = (window -self.train_mean[i]) / self.train_std[i]\n",
    "            \n",
    "            item[self.currencies[i] + \"_window\"] = window\n",
    "            item[self.currencies[i] + \"_label\"]  = self.y[i][index+self.seq_len]\n",
    "            \n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = [TimeSeriesDataset(X, y, dtype, CURRENCY_LST, dataset_percentages, WINDOW_SIZE) for dtype in ['train', 'val', 'test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTC_window': tensor([[ 0.0153],\n",
       "         [-0.0210],\n",
       "         [-0.0309]]),\n",
       " 'BTC_label': tensor(0),\n",
       " 'ETH_window': tensor([[ 0.0418],\n",
       "         [-0.0312],\n",
       "         [-0.0541]]),\n",
       " 'ETH_label': tensor(0),\n",
       " 'LTC_window': tensor([[ 0.0551],\n",
       "         [-0.0383],\n",
       "         [-0.0459]]),\n",
       " 'LTC_label': tensor(0),\n",
       " 'ADA_window': tensor([[ 0.0194],\n",
       "         [-0.0520],\n",
       "         [-0.0475]]),\n",
       " 'ADA_label': tensor(0),\n",
       " 'XRP_window': tensor([[ 0.0144],\n",
       "         [-0.0430],\n",
       "         [-0.0473]]),\n",
       " 'XRP_label': tensor(0)}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>close</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>-0.022348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>0</td>\n",
       "      <td>0.033952</td>\n",
       "      <td>-0.014812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.005774</td>\n",
       "      <td>-0.063941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.085536</td>\n",
       "      <td>-0.097821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.049612</td>\n",
       "      <td>0.013399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.063291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.044194</td>\n",
       "      <td>-0.004187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.009738</td>\n",
       "      <td>-0.053603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.024161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.046426</td>\n",
       "      <td>-0.069453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            change_dir     close      diff\n",
       "0                                         \n",
       "2018-05-08           0  0.009369 -0.022348\n",
       "2018-05-09           0  0.033952 -0.014812\n",
       "2018-05-10           0 -0.005774 -0.063941\n",
       "2018-05-11           0 -0.085536 -0.097821\n",
       "2018-05-12           1 -0.049612  0.013399\n",
       "2018-05-13           1  0.030636  0.063291\n",
       "2018-05-14           0  0.044194 -0.004187\n",
       "2018-05-15           0 -0.009738 -0.053603\n",
       "2018-05-16           1  0.016912  0.024161\n",
       "2018-05-17           0 -0.046426 -0.069453"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['XRP'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>close</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>-0.019129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028866</td>\n",
       "      <td>0.013239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010518</td>\n",
       "      <td>-0.033620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.047594</td>\n",
       "      <td>-0.069237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.028022</td>\n",
       "      <td>0.007819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.024937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027039</td>\n",
       "      <td>-0.001888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>-0.023515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.005470</td>\n",
       "      <td>-0.015722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.038187</td>\n",
       "      <td>-0.035253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            change_dir     close      diff\n",
       "0                                         \n",
       "2018-05-08           0 -0.006207 -0.019129\n",
       "2018-05-09           1  0.028866  0.013239\n",
       "2018-05-10           0  0.010518 -0.033620\n",
       "2018-05-11           0 -0.047594 -0.069237\n",
       "2018-05-12           1 -0.028022  0.007819\n",
       "2018-05-13           1  0.012804  0.024937\n",
       "2018-05-14           0  0.027039 -0.001888\n",
       "2018-05-15           0  0.006275 -0.023515\n",
       "2018-05-16           0 -0.005470 -0.015722\n",
       "2018-05-17           0 -0.038187 -0.035253"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['BTC'].loc[common_range].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTC_window': tensor([[ 0.0289],\n",
       "         [ 0.0105],\n",
       "         [-0.0476],\n",
       "         [-0.0280],\n",
       "         [ 0.0128]]),\n",
       " 'BTC_label': tensor(0),\n",
       " 'ETH_window': tensor([[ 0.0266],\n",
       "         [-0.0008],\n",
       "         [-0.0611],\n",
       "         [-0.0419],\n",
       "         [ 0.0306]]),\n",
       " 'ETH_label': tensor(0),\n",
       " 'LTC_window': tensor([[ 0.0199],\n",
       "         [-0.0108],\n",
       "         [-0.0784],\n",
       "         [-0.0218],\n",
       "         [ 0.0141]]),\n",
       " 'LTC_label': tensor(1),\n",
       " 'ADA_window': tensor([[ 0.0521],\n",
       "         [-0.0066],\n",
       "         [-0.1058],\n",
       "         [-0.0344],\n",
       "         [ 0.0421]]),\n",
       " 'ADA_label': tensor(0),\n",
       " 'XRP_window': tensor([[ 0.0340],\n",
       "         [-0.0058],\n",
       "         [-0.0855],\n",
       "         [-0.0496],\n",
       "         [ 0.0306]]),\n",
       " 'XRP_label': tensor(0)}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1197)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.23393614e-03,  5.25757042e-04, -2.40121736e-04, -3.96297353e-05,\n",
       "       -1.21489488e-03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1000].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.530822\n",
       "0    0.469178\n",
       "Name: change_dir, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['BTC']['change_dir'].value_counts() / len(dfs['BTC'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf5a346d587ec1341992060547c85a6411ea706a55887781b800d60fda342a75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

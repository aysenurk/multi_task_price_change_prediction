{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(currency_lst,\n",
    "             n_classes,\n",
    "             frequency, \n",
    "             window_size,\n",
    "             neutral_quantile = 0.25,\n",
    "             beg_date = pd.Timestamp(2013,1,1),\n",
    "             end_date = pd.Timestamp.now(),\n",
    "             log_price = True,\n",
    "             remove_trend = True,\n",
    "             include_indicators = True,\n",
    "             include_imfs = True):\n",
    "        \n",
    "        X, y, dfs = {}, {}, {}     \n",
    "        \n",
    "        for cur in currency_lst:\n",
    "            df = pd.read_csv(f\"../data/0_raw/Binance/{str.lower(cur)}_usdt_1d.csv\", index_col=0)\n",
    "            df.index = pd.to_datetime(df.index, unit='s')\n",
    "            df.sort_index(inplace=True)\n",
    "            #df.index = df.Date.apply(pd.Timestamp)\n",
    "            #df.sort_values(\"Date\", inplace=True)\n",
    "            #df.set_index(\"Date\", inplace=True)\n",
    "            df.drop([\"Date\", \"Open\", \"High\", \"Low\"], axis=1, inplace=True)\n",
    "            df.rename(str.lower, axis=1, inplace=True)\n",
    "            \n",
    "            if log_price:\n",
    "                df[\"close\"] = df[\"close\"].apply(np.log)\n",
    "                   \n",
    "            if n_classes == 3:\n",
    "                df['pct_diff'] = df['close'].pct_change()\n",
    "                neutral_quantiles = df['pct_diff'].abs().quantile(neutral_quantile)\n",
    "                \n",
    "                conditions = [(df['pct_diff'] < 0) & (df['pct_diff'].abs() > neutral_quantiles),\n",
    "                              (df['pct_diff'] > 0) & (df['pct_diff'].abs() > neutral_quantiles)]\n",
    "\n",
    "                classes = [0,1] # 2 is the default class if none of conditions is met, i.e. price change in the neutral range\n",
    "            \n",
    "                change_dir = np.select(conditions, classes, default=2)\n",
    "            \n",
    "            else:\n",
    "                df['diff'] = df['close'].diff()\n",
    "                change_dir = df['diff'].apply(lambda x: 0 if x <= 0 else 1)\n",
    "                \n",
    "            if remove_trend:\n",
    "                from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "                components = seasonal_decompose(df[\"close\"], model=\"additive\")\n",
    "                df[\"close\"] -= components.trend\n",
    "            \n",
    "            df.insert(loc=0, column=\"change_dir\", value=change_dir)   \n",
    "            df.dropna(inplace=True)       \n",
    "            \n",
    "            if include_indicators:\n",
    "                from ta import add_all_ta_features\n",
    "                df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\n",
    "            else:\n",
    "                df.drop(\"volume\", axis=1, inplace=True)\n",
    "            \n",
    "            if include_imfs:\n",
    "                from PyEMD import EEMD\n",
    "                eemd = EEMD()\n",
    "                imfs = eemd(df[\"close\"].values)\n",
    "                imf_features = [\"imf_\"+str(i) for i in range(imfs.shape[0])]\n",
    "                df = pd.concat((df, pd.DataFrame(imfs.T, columns=imf_features, index=df.index)), axis=1)\n",
    "\n",
    "\n",
    "            dfs[cur] = df\n",
    "        \n",
    "        min_dates = [df.index.min() for cur, df in dfs.items()]\n",
    "        max_dates = [df.index.max() for cur, df in dfs.items()]\n",
    "        beg_date = max([max(min_dates), beg_date])\n",
    "        end_date = min([min(max_dates), end_date])\n",
    "        common_range = pd.date_range(beg_date, end_date, freq=frequency)\n",
    "        \n",
    "        diff_col = 'pct_diff' if n_classes == 3 else 'diff'\n",
    "        X = np.array([dfs[cur].loc[common_range].drop([\"change_dir\", diff_col], axis=1).values for cur in currency_lst])\n",
    "        y = np.array([dfs[cur].loc[common_range, \"change_dir\"].values for cur in currency_lst])\n",
    "        features = df.columns.tolist()\n",
    "        \n",
    "        return X, y, features, dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_LST = ['BTC', 'ETH', 'LTC']\n",
    "N_CLASSES = 3\n",
    "FREQUENCY = \"D\"\n",
    "WINDOW_SIZE = 50\n",
    "NEUTRAL_QUANTILE = 0.33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features, dfs = get_data(CURRENCY_LST,\n",
    "                               N_CLASSES,\n",
    "                                 FREQUENCY, \n",
    "                                 WINDOW_SIZE,\n",
    "                                 neutral_quantile = NEUTRAL_QUANTILE,\n",
    "                                 log_price=True,\n",
    "                                 remove_trend=False,\n",
    "                                 include_indicators = False,\n",
    "                                 include_imfs = False\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3, 1241, 1), (3, 1241))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.7010641 ],\n",
       "       [ 9.77222957],\n",
       "       [ 9.85758287],\n",
       "       ...,\n",
       "       [10.95842848],\n",
       "       [10.94011237],\n",
       "       [10.93067562]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.366446\n",
       "2    0.330390\n",
       "0    0.303164\n",
       "Name: change_dir, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the first WINDOW_SIZE values of change direction will be seen as NaN \n",
    "\n",
    "dfs['BTC']['change_dir'].value_counts() / len(dfs['BTC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CURRENCIES = 3\n",
    "INPUT_FEATURE_SIZE = 1\n",
    "WINDOW_SIZE = 50\n",
    "TRAIN_PERCENTAGE, VAL_PERCENTAGE, TEST_PERCENTAGE = 0.70, 0.15, 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 x: np.ndarray,\n",
    "                 y: np.ndarray,\n",
    "                 data_use_type,\n",
    "                 train_percentage = TRAIN_PERCENTAGE,\n",
    "                 val_percentage = VAL_PERCENTAGE,\n",
    "                 test_percentage = TEST_PERCENTAGE,\n",
    "                 seq_len = WINDOW_SIZE, \n",
    "                 ):\n",
    "        \n",
    "        self.x = torch.tensor(x).float()\n",
    "        self.y = torch.tensor(y).float()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.data_use_type = data_use_type\n",
    "        \n",
    "        #self.train_size = int(len(self.x) * train_percentage)\n",
    "        self.val_size = int(len(self.x) * val_percentage)\n",
    "        self.test_size = int(len(self.x) * test_percentage)\n",
    "        self.train_size = len(self.x) - self.val_size - self.test_size \n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        if self.data_use_type == \"train\":\n",
    "            return self.train_size - self.seq_len\n",
    "        \n",
    "        elif self.data_use_type == \"val\":\n",
    "            return self.val_size \n",
    "        \n",
    "        else:\n",
    "            return self.test_size\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self.data_use_type ==\"val\":\n",
    "            index = self.train_size + index - self.seq_len\n",
    "            \n",
    "        elif self.data_use_type ==\"test\":\n",
    "            index = self.train_size + self.val_size + index - self.seq_len\n",
    "        \n",
    "        window = self.x[index:index+self.seq_len]\n",
    "        price_change = self.y[index+self.seq_len]\n",
    "        \n",
    "        return (window, price_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets for the currency at 0 index of X\n",
    "train, val, test = [TimeSeriesDataset(X[0], y[0], dtype) for dtype in ['train', 'val', 'test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1235"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train) + len(val) + len(test) + WINDOW_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-9.7841],\n",
       "         [-9.7766],\n",
       "         [-9.7373],\n",
       "         [-9.6856],\n",
       "         [-9.6378],\n",
       "         [-9.5922],\n",
       "         [-9.5783],\n",
       "         [-9.5691],\n",
       "         [-9.5564],\n",
       "         [-9.5673],\n",
       "         [-9.5577],\n",
       "         [-9.5600],\n",
       "         [-9.5566],\n",
       "         [-9.5471],\n",
       "         [-9.5420],\n",
       "         [-9.5506],\n",
       "         [-9.5742],\n",
       "         [-9.6194],\n",
       "         [-9.6427],\n",
       "         [-9.6581],\n",
       "         [-9.6554],\n",
       "         [-9.6553],\n",
       "         [-9.6369],\n",
       "         [-9.6068],\n",
       "         [-9.5806],\n",
       "         [-9.5547],\n",
       "         [-9.5410],\n",
       "         [-9.5013],\n",
       "         [-9.4577],\n",
       "         [-9.4307],\n",
       "         [-9.4050],\n",
       "         [-9.3901],\n",
       "         [-9.3678],\n",
       "         [-9.3350],\n",
       "         [-9.3336],\n",
       "         [-9.3383],\n",
       "         [-9.3410],\n",
       "         [-9.3361],\n",
       "         [-9.3207],\n",
       "         [-9.3250],\n",
       "         [-9.3314],\n",
       "         [-9.3237],\n",
       "         [-9.3097],\n",
       "         [-9.2822],\n",
       "         [-9.2504],\n",
       "         [-9.2186],\n",
       "         [-9.1654],\n",
       "         [-9.0964],\n",
       "         [-9.0548],\n",
       "         [-9.0116]]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTimeSeriesDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 n_currencies,\n",
    "                 x: np.ndarray, \n",
    "                 y: np.ndarray,\n",
    "                 data_use_type,\n",
    "                 train_percentage = TRAIN_PERCENTAGE,\n",
    "                 val_percentage = VAL_PERCENTAGE,\n",
    "                 test_percentage = TEST_PERCENTAGE,\n",
    "                 seq_len = WINDOW_SIZE, \n",
    "                 ):\n",
    "        \n",
    "        self.x = torch.tensor(x[:n_currencies]).float()\n",
    "        self.y = torch.tensor(y[:n_currencies]).float()\n",
    "        self.seq_len = seq_len\n",
    "        self.data_use_type = data_use_type\n",
    "        \n",
    "        #self.train_size = int(len(self.x[0]) * train_percentage)\n",
    "        self.val_size = int(len(self.x[0]) * val_percentage)\n",
    "        self.test_size = int(len(self.x[0]) * test_percentage)\n",
    "        self.train_size = len(self.x[0]) - self.val_size - self.test_size \n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        if self.data_use_type == \"train\":\n",
    "            return self.train_size - ( self.seq_len)\n",
    "\n",
    "        elif self.data_use_type == \"val\":\n",
    "            return self.val_size\n",
    "  \n",
    "        else:\n",
    "            return self.test_size\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        item = dict()\n",
    "        \n",
    "        if self.data_use_type ==\"val\":\n",
    "            index = self.train_size + index - self.seq_len\n",
    "            \n",
    "        elif self.data_use_type ==\"test\":\n",
    "            index = self.train_size + self.val_size + index - self.seq_len\n",
    "        \n",
    "        for i in range(N_CURRENCIES):\n",
    "            item[\"currency_\" + str(i) + \"_window\"] = self.x[i][index:index+self.seq_len]\n",
    "            item[\"currency_\" + str(i) + \"_label\"]  = self.y[i][index+self.seq_len]\n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = [MultiTimeSeriesDataset(N_CURRENCIES, X, y, dtype) \n",
    "                    for dtype in ['train', 'val', 'test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'currency_0_window': tensor([[-9.7841],\n",
       "         [-9.7766],\n",
       "         [-9.7373],\n",
       "         [-9.6856],\n",
       "         [-9.6378],\n",
       "         [-9.5922],\n",
       "         [-9.5783],\n",
       "         [-9.5691],\n",
       "         [-9.5564],\n",
       "         [-9.5673],\n",
       "         [-9.5577],\n",
       "         [-9.5600],\n",
       "         [-9.5566],\n",
       "         [-9.5471],\n",
       "         [-9.5420],\n",
       "         [-9.5506],\n",
       "         [-9.5742],\n",
       "         [-9.6194],\n",
       "         [-9.6427],\n",
       "         [-9.6581],\n",
       "         [-9.6554],\n",
       "         [-9.6553],\n",
       "         [-9.6369],\n",
       "         [-9.6068],\n",
       "         [-9.5806],\n",
       "         [-9.5547],\n",
       "         [-9.5410],\n",
       "         [-9.5013],\n",
       "         [-9.4577],\n",
       "         [-9.4307],\n",
       "         [-9.4050],\n",
       "         [-9.3901],\n",
       "         [-9.3678],\n",
       "         [-9.3350],\n",
       "         [-9.3336],\n",
       "         [-9.3383],\n",
       "         [-9.3410],\n",
       "         [-9.3361],\n",
       "         [-9.3207],\n",
       "         [-9.3250],\n",
       "         [-9.3314],\n",
       "         [-9.3237],\n",
       "         [-9.3097],\n",
       "         [-9.2822],\n",
       "         [-9.2504],\n",
       "         [-9.2186],\n",
       "         [-9.1654],\n",
       "         [-9.0964],\n",
       "         [-9.0548],\n",
       "         [-9.0116]]),\n",
       " 'currency_0_label': tensor(0.),\n",
       " 'currency_1_window': tensor([[-6.5919],\n",
       "         [-6.6120],\n",
       "         [-6.6035],\n",
       "         [-6.5943],\n",
       "         [-6.5839],\n",
       "         [-6.5708],\n",
       "         [-6.5619],\n",
       "         [-6.5525],\n",
       "         [-6.5382],\n",
       "         [-6.5587],\n",
       "         [-6.5675],\n",
       "         [-6.5831],\n",
       "         [-6.5909],\n",
       "         [-6.6097],\n",
       "         [-6.6429],\n",
       "         [-6.6834],\n",
       "         [-6.7217],\n",
       "         [-6.7772],\n",
       "         [-6.8379],\n",
       "         [-6.8959],\n",
       "         [-6.9547],\n",
       "         [-6.9960],\n",
       "         [-7.0235],\n",
       "         [-7.0617],\n",
       "         [-7.1080],\n",
       "         [-7.1339],\n",
       "         [-7.1503],\n",
       "         [-7.1138],\n",
       "         [-7.0823],\n",
       "         [-7.0629],\n",
       "         [-7.0351],\n",
       "         [-7.0086],\n",
       "         [-6.9729],\n",
       "         [-6.9376],\n",
       "         [-6.9347],\n",
       "         [-6.9432],\n",
       "         [-6.9519],\n",
       "         [-6.9544],\n",
       "         [-6.9502],\n",
       "         [-6.9755],\n",
       "         [-6.9997],\n",
       "         [-7.0143],\n",
       "         [-7.0227],\n",
       "         [-7.0207],\n",
       "         [-7.0020],\n",
       "         [-6.9818],\n",
       "         [-6.9219],\n",
       "         [-6.8473],\n",
       "         [-6.7999],\n",
       "         [-6.7428]]),\n",
       " 'currency_1_label': tensor(0.),\n",
       " 'currency_2_window': tensor([[-5.7309],\n",
       "         [-5.7456],\n",
       "         [-5.7230],\n",
       "         [-5.7018],\n",
       "         [-5.6777],\n",
       "         [-5.6350],\n",
       "         [-5.6069],\n",
       "         [-5.5866],\n",
       "         [-5.5565],\n",
       "         [-5.5491],\n",
       "         [-5.5195],\n",
       "         [-5.4964],\n",
       "         [-5.4736],\n",
       "         [-5.4569],\n",
       "         [-5.4433],\n",
       "         [-5.4363],\n",
       "         [-5.4377],\n",
       "         [-5.4791],\n",
       "         [-5.5054],\n",
       "         [-5.5235],\n",
       "         [-5.5219],\n",
       "         [-5.5271],\n",
       "         [-5.5213],\n",
       "         [-5.5168],\n",
       "         [-5.5075],\n",
       "         [-5.4877],\n",
       "         [-5.4740],\n",
       "         [-5.4297],\n",
       "         [-5.3860],\n",
       "         [-5.3597],\n",
       "         [-5.3316],\n",
       "         [-5.3024],\n",
       "         [-5.2727],\n",
       "         [-5.2364],\n",
       "         [-5.2346],\n",
       "         [-5.2334],\n",
       "         [-5.2282],\n",
       "         [-5.2171],\n",
       "         [-5.1965],\n",
       "         [-5.2014],\n",
       "         [-5.2041],\n",
       "         [-5.1969],\n",
       "         [-5.1839],\n",
       "         [-5.1520],\n",
       "         [-5.1097],\n",
       "         [-5.0915],\n",
       "         [-5.0500],\n",
       "         [-4.9969],\n",
       "         [-4.9717],\n",
       "         [-4.9452]]),\n",
       " 'currency_2_label': tensor(2.)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first day data for multi-task learning\n",
    "train[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

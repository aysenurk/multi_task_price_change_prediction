{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from TimeSeriesLearningUtils import TimeSeriesDataset\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(currency_list,\n",
    "             data_frequency,\n",
    "             pred_frequency, \n",
    "             num_classes,\n",
    "             window_size,\n",
    "             neutral_quantile = 0.33,\n",
    "             beg_date = pd.Timestamp(2017,1,1),\n",
    "             end_date = pd.Timestamp.now(),\n",
    "             log_price = True,\n",
    "             remove_trend = False,\n",
    "             decompose = False,\n",
    "             ma_period = 0,\n",
    "             indicators = False,\n",
    "             imfs = False,\n",
    "             ohlv = False,\n",
    "              **kwargs):\n",
    "\n",
    "        X, y, dfs = {}, {}, {}     \n",
    "        \n",
    "        for cur in currency_list:\n",
    "            df = pd.read_csv(f\"../data/0_raw/Binance/{str.lower(cur)}_usdt_{data_frequency}.csv\", header=None,index_col=0)\n",
    "            df.index = pd.to_datetime(df.index, unit='ms')\n",
    "            df.sort_index(inplace=True)\n",
    "            df.columns = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "            \n",
    "            if indicators:\n",
    "                from ta import add_all_ta_features\n",
    "                indicators_df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\n",
    "                df[indicators_df.columns] = indicators_df\n",
    "          \n",
    "            if imfs:\n",
    "                from PyEMD import EEMD\n",
    "                eemd = EEMD(parallel=True, processes=2)\n",
    "                imfs_result = eemd(df[\"close\"].values, max_imf=7)\n",
    "                imf_features = [\"imf_\"+str(i) for i in range(imfs_result.shape[0])]\n",
    "                df = pd.concat((df, pd.DataFrame(imfs_result.T, columns=imf_features, index=df.index)), axis=1)\n",
    "            \n",
    "            if log_price:\n",
    "                df[[\"close\", \"open\", \"high\", \"low\"]] = df[[\"close\", \"open\", \"high\", \"low\"]].apply(np.log, axis=1)\n",
    "                   \n",
    "            if num_classes == 3:\n",
    "                pct_diff = df['close'].pct_change()\n",
    "                quantile_value = pct_diff.abs().quantile(neutral_quantile).loc[neutral_quantile]\n",
    "                \n",
    "                conditions = [(pct_diff < 0) & (pct_diff.abs() > quantile_value),\n",
    "                              (pct_diff > 0) & (pct_diff.abs() > quantile_value)]\n",
    "\n",
    "                classes = [0,1] # 2 is the default class if none of conditions is met, i.e. price change in the neutral range\n",
    "            \n",
    "                change_dir = np.select(conditions, classes, default=2)\n",
    "            \n",
    "            else: \n",
    "                change_dir = df['close'].diff().apply(lambda x: 0 if x <= 0 else 1)\n",
    "            \n",
    "            df.insert(loc=0, column=\"change_dir\", value=change_dir)   \n",
    "            \n",
    "            if remove_trend:\n",
    "                #from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "                #ma_period = ma_period if pred_frequency in ['d', 'D'] else ma_period * 4\n",
    "                #components = seasonal_decompose(df[\"close\"], model=\"additive\", period = ma_period, two_sided=False)\n",
    "                #df[\"close\"] -= components.trend\n",
    "                df['diff'] = df['close'].diff()\n",
    "                #df['diff'] = df['close'].pct_change()\n",
    "                df.drop('close', axis=1, inplace=True)\n",
    "                df.dropna(inplace=True) \n",
    "\n",
    "            if decompose: \n",
    "                from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "                ma_period = ma_period if pred_frequency in ['d', 'D'] else ma_period * 4 #if pred_frequency is 6h, then multiply the ma_period by 4 \n",
    "                components = seasonal_decompose(df[\"close\"], model=\"additive\", period = ma_period, two_sided=False)\n",
    "                df['trend'] = components.trend\n",
    "                df['residual'] = components.resid  \n",
    "                df['seasonal'] = components.seasonal\n",
    "                df.dropna(inplace=True)  \n",
    "\n",
    "            if not ohlv: #keeping open, high, low, and volume\n",
    "                df.drop([\"open\", \"high\", \"low\", \"volume\"], axis=1, inplace=True)\n",
    "\n",
    "            dfs[cur] = df\n",
    "        \n",
    "        min_dates = [df.index.min() for cur, df in dfs.items()]\n",
    "        max_dates = [df.index.max() for cur, df in dfs.items()]\n",
    "        beg_date = max([max(min_dates), beg_date])\n",
    "        end_date = min([min(max_dates), end_date])\n",
    "        common_range = pd.date_range(beg_date, end_date, freq=pred_frequency)\n",
    "        \n",
    "        missing = set()\n",
    "        common_set = set(common_range)\n",
    "        for cur, df in dfs.items():\n",
    "            missing_steps = common_set.difference(df.index)\n",
    "            missing |= missing_steps\n",
    "        common_range = common_range.drop(missing)\n",
    "        \n",
    "        X = np.array([dfs[cur].loc[common_range].drop([\"change_dir\"], axis=1).values for cur in currency_list])\n",
    "        y = np.array([dfs[cur].loc[common_range, \"change_dir\"].values for cur in currency_list])\n",
    "        features = df.columns.tolist()\n",
    "        features.remove(\"change_dir\")\n",
    "\n",
    "        return X, y, features, dfs, common_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data2(currency_list,\n",
    "             data_frequency,\n",
    "             pred_frequency, \n",
    "             num_classes,\n",
    "             window_size,\n",
    "             neutral_quantile = 0.33,\n",
    "             beg_date = pd.Timestamp(2017,1,1),\n",
    "             end_date = pd.Timestamp.now(),\n",
    "             log_price = True,\n",
    "             remove_trend = False,\n",
    "             ma_period = 0,\n",
    "             include_indicators = False,\n",
    "             include_imfs = False,\n",
    "             ohlv = False,\n",
    "             drop_missing = True,\n",
    "              **kwargs):\n",
    "\n",
    "        X, y, dfs = {}, {}, {}     \n",
    "        \n",
    "        for cur in currency_list:\n",
    "            df = pd.read_csv(f\"../data/0_raw/Binance/{str.lower(cur)}_usdt_{data_frequency}.csv\", header=None,index_col=0)\n",
    "            df.index = pd.to_datetime(df.index, unit='ms')\n",
    "            df.sort_index(inplace=True)\n",
    "            df.columns = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "            \n",
    "            if include_indicators:\n",
    "                from ta import add_all_ta_features\n",
    "                indicators_df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\n",
    "                df[indicators_df.columns] = indicators_df\n",
    "            \n",
    "            if include_imfs:\n",
    "                from PyEMD import EEMD\n",
    "                eemd = EEMD(parallel=True, processes=2)\n",
    "                imfs = eemd(df[\"close\"].values, max_imf=7)\n",
    "                imf_features = [\"imf_\"+str(i) for i in range(imfs.shape[0])]\n",
    "                df = pd.concat((df, pd.DataFrame(imfs.T, columns=imf_features, index=df.index)), axis=1)\n",
    "            \n",
    "            if log_price:\n",
    "                df[[\"close\", \"open\", \"high\", \"low\"]] = df[[\"close\", \"open\", \"high\", \"low\"]].apply(np.log, axis=1)\n",
    "                   \n",
    "            if num_classes == 3:\n",
    "                df['pct_diff'] = df['close'].pct_change()\n",
    "                neutral_quantiles = df['pct_diff'].abs().quantile(neutral_quantile).loc[neutral_quantile]\n",
    "\n",
    "                conditions = [(df['pct_diff'] < 0) & (df['pct_diff'].abs() > neutral_quantiles),\n",
    "                              (df['pct_diff'] > 0) & (df['pct_diff'].abs() > neutral_quantiles)]\n",
    "\n",
    "                classes = [0,1] # 2 is the default class if none of conditions is met, i.e. price change in the neutral range\n",
    "            \n",
    "                change_dir = np.select(conditions, classes, default=2)\n",
    "            \n",
    "            else:\n",
    "                df['diff'] = df['close'].diff()\n",
    "                change_dir = df['diff'].apply(lambda x: 0 if x <= 0 else 1)\n",
    "            \n",
    "            df.insert(loc=0, column=\"change_dir\", value=change_dir)   \n",
    "            df.dropna(inplace=True)  \n",
    "            \n",
    "            if remove_trend:\n",
    "                from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "                components = seasonal_decompose(df[\"close\"].values, period=3, model=\"additive\")#, period = ma_period, two_sided=False)\n",
    "                df[\"close\"] -= components.trend\n",
    "                df.dropna(inplace=True)\n",
    "                \n",
    "            if not ohlv: #keeping open, high, low, and volume\n",
    "                df.drop([\"open\", \"high\", \"low\", \"volume\"], axis=1, inplace=True)\n",
    "\n",
    "            dfs[cur] = df\n",
    "        \n",
    "        min_dates = [df.index.min() for cur, df in dfs.items()]\n",
    "        max_dates = [df.index.max() for cur, df in dfs.items()]\n",
    "        beg_date = max([max(min_dates), beg_date])\n",
    "        end_date = min([min(max_dates), end_date])\n",
    "        common_range = pd.date_range(beg_date, end_date, freq=pred_frequency)\n",
    "        \n",
    "        missing = set()\n",
    "        common_set = set(common_range)\n",
    "        for cur, df in dfs.items():\n",
    "            missing_steps = common_set.difference(df.index)\n",
    "            missing |= missing_steps\n",
    "        common_range = common_range.drop(missing)\n",
    "        \n",
    "        diff_col = 'pct_diff' if num_classes == 3 else 'diff'\n",
    "\n",
    "        X = np.array([dfs[cur].loc[common_range].drop([\"change_dir\", diff_col], axis=1).values for cur in currency_list])\n",
    "        y = np.array([dfs[cur].loc[common_range, \"change_dir\"].values for cur in currency_list])\n",
    "        features = df.columns.tolist()\n",
    "        features.remove(\"change_dir\")\n",
    "        \n",
    "        return X, y, features, dfs, common_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENCY_LST = ['BTC', 'ETH', 'LTC', 'XRP', 'ADA']\n",
    "num_classes = 2\n",
    "FREQUENCY = \"d\"\n",
    "WINDOW_SIZE = 400\n",
    "NEUTRAL_QUANTILE = 0.33,\n",
    "dataset_percentages = [0.90, 0.05, 0.05]\n",
    "train_pct = 0.8\n",
    "LOOK_AHEAD = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, features, dfs, common_range = get_data(currency_list= CURRENCY_LST,\n",
    "                               data_frequency='1d',\n",
    "                               pred_frequency=FREQUENCY,\n",
    "                               num_classes = num_classes, \n",
    "                               window_size = WINDOW_SIZE,\n",
    "                               neutral_quantile = NEUTRAL_QUANTILE,\n",
    "                               log_price = True,\n",
    "                               remove_trend = True,\n",
    "                               ma_period = 7,\n",
    "                               indicators = False,\n",
    "                               imfs = False,\n",
    "                               decompose = False,\n",
    "                               ohlv = False,\n",
    "                               beg_date = pd.Timestamp(2017,1,1),\n",
    "                               end_date = pd.Timestamp(2022,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1197, 1)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.022603</td>\n",
       "      <td>0.001648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.798497</td>\n",
       "      <td>0.043587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.502607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.019939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.202952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        change_dir         diff\n",
       "count  1460.000000  1460.000000\n",
       "mean      1.022603     0.001648\n",
       "std       0.798497     0.043587\n",
       "min       0.000000    -0.502607\n",
       "25%       0.000000    -0.015750\n",
       "50%       1.000000     0.001810\n",
       "75%       2.000000     0.019939\n",
       "max       2.000000     0.202952"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dfs['BTC']\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window(a, window):\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.18 in c:\\users\\furkan\\appdata\\roaming\\python\\python38\\site-packages (1.18.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U numpy==1.18 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC\n",
      "0.9984152139461173\n",
      "0.8501805054151624\n",
      "ETH\n",
      "1.0\n",
      "0.8483754512635379\n",
      "LTC\n",
      "0.9857369255150554\n",
      "0.8537906137184116\n",
      "XRP\n",
      "0.9667194928684627\n",
      "0.8393501805054152\n",
      "ADA\n",
      "0.9841521394611727\n",
      "0.8375451263537906\n"
     ]
    }
   ],
   "source": [
    "LOOK_AHEAD=6\n",
    "data = {}\n",
    "for i, cur in enumerate(CURRENCY_LST):\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\n",
    "    \n",
    "    train_size = int(len(seq_X) * train_pct)\n",
    "    test_size = len(seq_X) - train_size\n",
    "\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\n",
    "    X_train = seq_X[:train_size]\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\n",
    "    y_test = y[i][train_size:]\n",
    "    lr = LogisticRegression()\n",
    "    lr.fit(X_train[:-LOOK_AHEAD], y_train[LOOK_AHEAD:])\n",
    "    print(cur)\n",
    "    #print(lr.coef_)\n",
    "    print(lr.score(X_train[:-LOOK_AHEAD], y_train[LOOK_AHEAD:]))\n",
    "    print(lr.score(X_test[:-LOOK_AHEAD], y_test[LOOK_AHEAD:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC\n",
      "0.9937205651491365\n",
      "0.8678571428571429\n",
      "ETH\n",
      "1.0\n",
      "0.8517857142857143\n",
      "LTC\n",
      "0.9858712715855573\n",
      "0.8553571428571428\n",
      "XRP\n",
      "0.9811616954474097\n",
      "0.85\n",
      "ADA\n",
      "0.9968602825745683\n",
      "0.8589285714285714\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for i, cur in enumerate(CURRENCY_LST):\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\n",
    "\n",
    "    train_size = int(len(seq_X) * train_pct)\n",
    "    test_size = len(seq_X) - train_size\n",
    "\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\n",
    "    X_train = seq_X[:train_size]\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\n",
    "    y_test = y[i][train_size:]\n",
    "    lr = LogisticRegression(max_iter=1000)\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(cur)\n",
    "    #print(lr.coef_)\n",
    "    print(lr.score(X_train, y_train))\n",
    "    print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC\n",
      "1.0\n",
      "0.8410714285714286\n",
      "ETH\n",
      "1.0\n",
      "0.8517857142857143\n",
      "LTC\n",
      "1.0\n",
      "0.8678571428571429\n",
      "XRP\n",
      "1.0\n",
      "0.8553571428571428\n",
      "ADA\n",
      "1.0\n",
      "0.8678571428571429\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for i, cur in enumerate(CURRENCY_LST):\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\n",
    "    \n",
    "    train_size = int(len(seq_X) * train_pct)\n",
    "    test_size = len(seq_X) - train_size\n",
    "\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\n",
    "    X_train = seq_X[:train_size]\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\n",
    "    y_test = y[i][train_size:]\n",
    "    rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1)\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(cur)\n",
    "    print(rf.score(X_train, y_train))\n",
    "    print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(rf.feature_importances_).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC\n",
      "1.0\n",
      "0.6985294117647058\n",
      "ETH\n",
      "1.0\n",
      "0.6691176470588235\n",
      "LTC\n",
      "1.0\n",
      "0.6617647058823529\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for i, cur in enumerate(CURRENCY_LST):\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\n",
    "    \n",
    "    train_size = int(len(seq_X) * train_pct)\n",
    "    test_size = len(seq_X) - train_size\n",
    "\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\n",
    "    X_train = seq_X[:train_size]\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\n",
    "    y_test = y[i][train_size:]\n",
    "    xgb = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', n_jobs=-1)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    print(cur)\n",
    "    print(xgb.score(X_train, y_train))\n",
    "    print(xgb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "43/43 - 8s - loss: 0.6946 - acc: 0.4862 - val_loss: 0.6944 - val_acc: 0.4853\n",
      "Epoch 2/30\n",
      "43/43 - 1s - loss: 0.6924 - acc: 0.4993 - val_loss: 0.6954 - val_acc: 0.4669\n",
      "Epoch 3/30\n",
      "43/43 - 1s - loss: 0.6902 - acc: 0.5371 - val_loss: 740462.1875 - val_acc: 0.5110\n",
      "Epoch 4/30\n",
      "43/43 - 1s - loss: 9852734.0000 - acc: 0.5240 - val_loss: 0.6964 - val_acc: 0.4412\n",
      "Epoch 5/30\n",
      "43/43 - 1s - loss: 0.6902 - acc: 0.5269 - val_loss: 0.6952 - val_acc: 0.4706\n",
      "Epoch 6/30\n",
      "43/43 - 1s - loss: 0.6900 - acc: 0.5153 - val_loss: 0.6967 - val_acc: 0.4522\n",
      "Epoch 7/30\n",
      "43/43 - 1s - loss: 0.6899 - acc: 0.5211 - val_loss: 0.6956 - val_acc: 0.4449\n",
      "Epoch 8/30\n",
      "43/43 - 1s - loss: 0.6898 - acc: 0.5124 - val_loss: 0.6954 - val_acc: 0.4449\n",
      "Epoch 9/30\n",
      "43/43 - 1s - loss: 0.6902 - acc: 0.5357 - val_loss: 0.6953 - val_acc: 0.4449\n",
      "Epoch 10/30\n",
      "43/43 - 1s - loss: 0.6896 - acc: 0.5342 - val_loss: 0.6947 - val_acc: 0.4412\n",
      "Epoch 11/30\n",
      "43/43 - 1s - loss: 0.6895 - acc: 0.5080 - val_loss: 0.6949 - val_acc: 0.4449\n",
      "Epoch 12/30\n",
      "43/43 - 1s - loss: 0.6895 - acc: 0.5284 - val_loss: 0.6954 - val_acc: 0.4449\n",
      "Epoch 13/30\n",
      "43/43 - 1s - loss: 0.6895 - acc: 0.5167 - val_loss: 0.6945 - val_acc: 0.4485\n",
      "Epoch 14/30\n",
      "43/43 - 1s - loss: 0.6897 - acc: 0.5298 - val_loss: 0.6940 - val_acc: 0.4853\n",
      "Epoch 15/30\n",
      "43/43 - 1s - loss: 0.6890 - acc: 0.5211 - val_loss: 0.6968 - val_acc: 0.4779\n",
      "Epoch 16/30\n",
      "43/43 - 1s - loss: 0.6891 - acc: 0.5357 - val_loss: 0.6951 - val_acc: 0.4559\n",
      "Epoch 17/30\n",
      "43/43 - 2s - loss: 0.6889 - acc: 0.5182 - val_loss: 0.6945 - val_acc: 0.4559\n",
      "Epoch 18/30\n",
      "43/43 - 2s - loss: 0.6890 - acc: 0.5328 - val_loss: 0.6957 - val_acc: 0.4632\n",
      "Epoch 19/30\n",
      "43/43 - 1s - loss: 0.6888 - acc: 0.5429 - val_loss: 0.6956 - val_acc: 0.4632\n",
      "Epoch 20/30\n",
      "43/43 - 1s - loss: 0.6883 - acc: 0.5153 - val_loss: 0.6945 - val_acc: 0.4743\n",
      "Epoch 21/30\n",
      "43/43 - 1s - loss: 0.6883 - acc: 0.5604 - val_loss: 0.6935 - val_acc: 0.4853\n",
      "Epoch 22/30\n",
      "43/43 - 1s - loss: 0.6876 - acc: 0.5575 - val_loss: 0.6952 - val_acc: 0.4743\n",
      "Epoch 23/30\n",
      "43/43 - 1s - loss: 0.6883 - acc: 0.5211 - val_loss: 0.6932 - val_acc: 0.4853\n",
      "Epoch 24/30\n",
      "43/43 - 1s - loss: 0.6876 - acc: 0.5575 - val_loss: 0.6943 - val_acc: 0.4853\n",
      "Epoch 25/30\n",
      "43/43 - 1s - loss: 0.6875 - acc: 0.5357 - val_loss: 0.6926 - val_acc: 0.5184\n",
      "Epoch 26/30\n",
      "43/43 - 1s - loss: 0.6871 - acc: 0.5429 - val_loss: 0.6910 - val_acc: 0.5368\n",
      "Epoch 27/30\n",
      "43/43 - 1s - loss: 0.6859 - acc: 0.5546 - val_loss: 1965766528.0000 - val_acc: 0.4926\n",
      "Epoch 28/30\n",
      "43/43 - 1s - loss: 16450657.0000 - acc: 0.5284 - val_loss: 0.7156 - val_acc: 0.4596\n",
      "Epoch 29/30\n",
      "43/43 - 1s - loss: 0.6900 - acc: 0.5357 - val_loss: 0.7007 - val_acc: 0.4853\n",
      "Epoch 30/30\n",
      "43/43 - 1s - loss: 0.6884 - acc: 0.5182 - val_loss: 0.6982 - val_acc: 0.5110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x259b5456c70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 16\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(WINDOW_SIZE, 1))))\n",
    "#model.add(Bidirectional(LSTM(100, activation='relu', input_shape=(200,WINDOW_SIZE, 1))))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "# fit model\n",
    "model.fit(X_train.reshape(X_train.shape[0],-1,1), \n",
    "          y_train, \n",
    "          epochs=30, \n",
    "          batch_size=batch_size, \n",
    "          verbose=2,\n",
    "         validation_data=(X_test.reshape(X_test.shape[0],-1,1), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(684, 100, 1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(X_train.shape[0],-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "80/80 - 1s - loss: 0.8170 - acc: 0.5149 - val_loss: 0.5435 - val_acc: 0.7607\n",
      "Epoch 2/20\n",
      "80/80 - 0s - loss: 0.3954 - acc: 0.8854 - val_loss: 0.4351 - val_acc: 0.8500\n",
      "Epoch 3/20\n",
      "80/80 - 0s - loss: 0.2376 - acc: 0.9733 - val_loss: 0.3938 - val_acc: 0.8661\n",
      "Epoch 4/20\n",
      "80/80 - 0s - loss: 0.1453 - acc: 1.0000 - val_loss: 0.3799 - val_acc: 0.8643\n",
      "Epoch 5/20\n",
      "80/80 - 0s - loss: 0.0862 - acc: 1.0000 - val_loss: 0.3851 - val_acc: 0.8625\n",
      "Epoch 6/20\n",
      "80/80 - 0s - loss: 0.0554 - acc: 1.0000 - val_loss: 0.3951 - val_acc: 0.8625\n",
      "Epoch 7/20\n",
      "80/80 - 0s - loss: 0.0375 - acc: 1.0000 - val_loss: 0.4101 - val_acc: 0.8643\n",
      "Epoch 8/20\n",
      "80/80 - 0s - loss: 0.0270 - acc: 1.0000 - val_loss: 0.4237 - val_acc: 0.8643\n",
      "Epoch 9/20\n",
      "80/80 - 0s - loss: 0.0201 - acc: 1.0000 - val_loss: 0.4388 - val_acc: 0.8643\n",
      "Epoch 10/20\n",
      "80/80 - 0s - loss: 0.0157 - acc: 1.0000 - val_loss: 0.4516 - val_acc: 0.8643\n",
      "Epoch 11/20\n",
      "80/80 - 0s - loss: 0.0125 - acc: 1.0000 - val_loss: 0.4640 - val_acc: 0.8643\n",
      "Epoch 12/20\n",
      "80/80 - 0s - loss: 0.0102 - acc: 1.0000 - val_loss: 0.4750 - val_acc: 0.8643\n",
      "Epoch 13/20\n",
      "80/80 - 0s - loss: 0.0085 - acc: 1.0000 - val_loss: 0.4871 - val_acc: 0.8643\n",
      "Epoch 14/20\n",
      "80/80 - 0s - loss: 0.0071 - acc: 1.0000 - val_loss: 0.4978 - val_acc: 0.8643\n",
      "Epoch 15/20\n",
      "80/80 - 0s - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5080 - val_acc: 0.8643\n",
      "Epoch 16/20\n",
      "80/80 - 0s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5170 - val_acc: 0.8643\n",
      "Epoch 17/20\n",
      "80/80 - 0s - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5259 - val_acc: 0.8643\n",
      "Epoch 18/20\n",
      "80/80 - 0s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5350 - val_acc: 0.8643\n",
      "Epoch 19/20\n",
      "80/80 - 0s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5430 - val_acc: 0.8643\n",
      "Epoch 20/20\n",
      "80/80 - 0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.5511 - val_acc: 0.8643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20a2ee9d1f0>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 8\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=batch_size, verbose=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.reshape(-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 200, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape(X_train.shape[0],-1,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 100, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(X_train, 2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>close</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.024659</td>\n",
       "      <td>-0.017351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.024570</td>\n",
       "      <td>0.005958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.013072</td>\n",
       "      <td>0.018154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.027246</td>\n",
       "      <td>0.047933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>-0.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-26</th>\n",
       "      <td>1</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.013172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-27</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.019464</td>\n",
       "      <td>-0.006344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-28</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.014760</td>\n",
       "      <td>0.017635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012603</td>\n",
       "      <td>0.044756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>-0.007075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            change_dir     close      diff\n",
       "0                                         \n",
       "2017-08-21           0 -0.024659 -0.017351\n",
       "2017-08-22           1 -0.024570  0.005958\n",
       "2017-08-23           1 -0.013072  0.018154\n",
       "2017-08-24           1  0.027246  0.047933\n",
       "2017-08-25           0  0.006414 -0.008219\n",
       "2017-08-26           1  0.001431  0.013172\n",
       "2017-08-27           0 -0.019464 -0.006344\n",
       "2017-08-28           1 -0.014760  0.017635\n",
       "2017-08-29           1  0.012603  0.044756\n",
       "2017-08-30           0  0.001160 -0.007075"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs2['BTC'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-21</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.017351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.005958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-23</th>\n",
       "      <td>1</td>\n",
       "      <td>0.018154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-24</th>\n",
       "      <td>1</td>\n",
       "      <td>0.047933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-25</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.008219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-09</th>\n",
       "      <td>1</td>\n",
       "      <td>0.054630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-10</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.014556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-11</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.001624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-12</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.024737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.073809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1454 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            change_dir      diff\n",
       "0                               \n",
       "2017-08-21           0 -0.017351\n",
       "2017-08-22           1  0.005958\n",
       "2017-08-23           1  0.018154\n",
       "2017-08-24           1  0.047933\n",
       "2017-08-25           0 -0.008219\n",
       "...                ...       ...\n",
       "2021-08-09           1  0.054630\n",
       "2021-08-10           0 -0.014556\n",
       "2021-08-11           0 -0.001624\n",
       "2021-08-12           0 -0.024737\n",
       "2021-08-13           1  0.073809\n",
       "\n",
       "[1454 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['BTC'].loc[dfs2['BTC'].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5, 1197, 5), (5, 1197))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 x: np.ndarray, \n",
    "                 y: np.ndarray,\n",
    "                 data_use_type,\n",
    "                 currency_list,\n",
    "                 dataset_percentages,\n",
    "                 window_size, \n",
    "                 **kwargs\n",
    "                 ):\n",
    "        self.currencies = currency_list\n",
    "        self.n_currencies = len(self.currencies)\n",
    "        self.x = torch.tensor(x[:self.n_currencies]).float()\n",
    "        self.y = torch.tensor(y[:self.n_currencies]).long()\n",
    "        self.seq_len = window_size\n",
    "        self.data_use_type = data_use_type\n",
    "        \n",
    "        train_percentage,val_percentage,test_percentage = dataset_percentages\n",
    "        self.train_size = int(len(self.x[0]) * train_percentage)\n",
    "        self.val_size = int(len(self.x[0]) * val_percentage)\n",
    "        self.test_size = len(self.x[0]) - self.train_size - self.val_size\n",
    "        \n",
    "        self.train_mean = [self.x[i][:self.train_size].mean(axis=0) for i in range(self.n_currencies)]\n",
    "        self.train_std = [self.x[i][:self.train_size].std(axis=0) for i in range(self.n_currencies)]\n",
    "        \n",
    "        #self.train_mean = self.x[:self.train_size].mean()\n",
    "        #self.train_std = self.x[:self.train_size].std()\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        if self.data_use_type == \"train\":\n",
    "            return self.train_size - ( self.seq_len)\n",
    "\n",
    "        elif self.data_use_type == \"val\":\n",
    "            return self.val_size \n",
    "        else:\n",
    "            return self.test_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        item = dict()\n",
    "        \n",
    "        if self.data_use_type ==\"val\":\n",
    "            index = self.train_size + index - self.seq_len\n",
    "            \n",
    "        elif self.data_use_type ==\"test\":\n",
    "            index = self.train_size + self.val_size + index - self.seq_len\n",
    "        \n",
    "        for i in range(self.n_currencies):\n",
    "            window = self.x[i][index:index+self.seq_len]\n",
    "            #window = (window -self.train_mean[i]) / self.train_std[i]\n",
    "            \n",
    "            item[self.currencies[i] + \"_window\"] = window\n",
    "            item[self.currencies[i] + \"_label\"]  = self.y[i][index+self.seq_len]\n",
    "            \n",
    "\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = [TimeSeriesDataset(X, y, dtype, CURRENCY_LST, dataset_percentages, WINDOW_SIZE) for dtype in ['train', 'val', 'test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTC_window': tensor([[ 0.0153],\n",
       "         [-0.0210],\n",
       "         [-0.0309]]),\n",
       " 'BTC_label': tensor(0),\n",
       " 'ETH_window': tensor([[ 0.0418],\n",
       "         [-0.0312],\n",
       "         [-0.0541]]),\n",
       " 'ETH_label': tensor(0),\n",
       " 'LTC_window': tensor([[ 0.0551],\n",
       "         [-0.0383],\n",
       "         [-0.0459]]),\n",
       " 'LTC_label': tensor(0),\n",
       " 'ADA_window': tensor([[ 0.0194],\n",
       "         [-0.0520],\n",
       "         [-0.0475]]),\n",
       " 'ADA_label': tensor(0),\n",
       " 'XRP_window': tensor([[ 0.0144],\n",
       "         [-0.0430],\n",
       "         [-0.0473]]),\n",
       " 'XRP_label': tensor(0)}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>close</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>0</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>-0.022348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>0</td>\n",
       "      <td>0.033952</td>\n",
       "      <td>-0.014812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.005774</td>\n",
       "      <td>-0.063941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.085536</td>\n",
       "      <td>-0.097821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.049612</td>\n",
       "      <td>0.013399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.030636</td>\n",
       "      <td>0.063291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.044194</td>\n",
       "      <td>-0.004187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.009738</td>\n",
       "      <td>-0.053603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.024161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.046426</td>\n",
       "      <td>-0.069453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            change_dir     close      diff\n",
       "0                                         \n",
       "2018-05-08           0  0.009369 -0.022348\n",
       "2018-05-09           0  0.033952 -0.014812\n",
       "2018-05-10           0 -0.005774 -0.063941\n",
       "2018-05-11           0 -0.085536 -0.097821\n",
       "2018-05-12           1 -0.049612  0.013399\n",
       "2018-05-13           1  0.030636  0.063291\n",
       "2018-05-14           0  0.044194 -0.004187\n",
       "2018-05-15           0 -0.009738 -0.053603\n",
       "2018-05-16           1  0.016912  0.024161\n",
       "2018-05-17           0 -0.046426 -0.069453"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['XRP'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>close</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-05-08</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.006207</td>\n",
       "      <td>-0.019129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-09</th>\n",
       "      <td>1</td>\n",
       "      <td>0.028866</td>\n",
       "      <td>0.013239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010518</td>\n",
       "      <td>-0.033620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-11</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.047594</td>\n",
       "      <td>-0.069237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-12</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.028022</td>\n",
       "      <td>0.007819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-13</th>\n",
       "      <td>1</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.024937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-14</th>\n",
       "      <td>0</td>\n",
       "      <td>0.027039</td>\n",
       "      <td>-0.001888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-15</th>\n",
       "      <td>0</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>-0.023515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-16</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.005470</td>\n",
       "      <td>-0.015722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-17</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.038187</td>\n",
       "      <td>-0.035253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            change_dir     close      diff\n",
       "0                                         \n",
       "2018-05-08           0 -0.006207 -0.019129\n",
       "2018-05-09           1  0.028866  0.013239\n",
       "2018-05-10           0  0.010518 -0.033620\n",
       "2018-05-11           0 -0.047594 -0.069237\n",
       "2018-05-12           1 -0.028022  0.007819\n",
       "2018-05-13           1  0.012804  0.024937\n",
       "2018-05-14           0  0.027039 -0.001888\n",
       "2018-05-15           0  0.006275 -0.023515\n",
       "2018-05-16           0 -0.005470 -0.015722\n",
       "2018-05-17           0 -0.038187 -0.035253"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['BTC'].loc[common_range].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BTC_window': tensor([[ 0.0289],\n",
       "         [ 0.0105],\n",
       "         [-0.0476],\n",
       "         [-0.0280],\n",
       "         [ 0.0128]]),\n",
       " 'BTC_label': tensor(0),\n",
       " 'ETH_window': tensor([[ 0.0266],\n",
       "         [-0.0008],\n",
       "         [-0.0611],\n",
       "         [-0.0419],\n",
       "         [ 0.0306]]),\n",
       " 'ETH_label': tensor(0),\n",
       " 'LTC_window': tensor([[ 0.0199],\n",
       "         [-0.0108],\n",
       "         [-0.0784],\n",
       "         [-0.0218],\n",
       "         [ 0.0141]]),\n",
       " 'LTC_label': tensor(1),\n",
       " 'ADA_window': tensor([[ 0.0521],\n",
       "         [-0.0066],\n",
       "         [-0.1058],\n",
       "         [-0.0344],\n",
       "         [ 0.0421]]),\n",
       " 'ADA_label': tensor(0),\n",
       " 'XRP_window': tensor([[ 0.0340],\n",
       "         [-0.0058],\n",
       "         [-0.0855],\n",
       "         [-0.0496],\n",
       "         [ 0.0306]]),\n",
       " 'XRP_label': tensor(0)}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 1197)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.23393614e-03,  5.25757042e-04, -2.40121736e-04, -3.96297353e-05,\n",
       "       -1.21489488e-03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:1000].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.530822\n",
       "0    0.469178\n",
       "Name: change_dir, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs['BTC']['change_dir'].value_counts() / len(dfs['BTC'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf5a346d587ec1341992060547c85a6411ea706a55887781b800d60fda342a75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

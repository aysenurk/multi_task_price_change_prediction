{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torch.utils.data import DataLoader, Dataset\r\n",
    "from src.TimeSeriesLearningUtils import *\r\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def get_data(currency_list,\r\n",
    "             data_frequency,\r\n",
    "             pred_frequency, \r\n",
    "             num_classes,\r\n",
    "             window_size,\r\n",
    "             neutral_quantile = 0.33,\r\n",
    "             beg_date = pd.Timestamp(2017,1,1),\r\n",
    "             end_date = pd.Timestamp.now(),\r\n",
    "             log_price = True,\r\n",
    "             remove_trend = False,\r\n",
    "             decompose = False,\r\n",
    "             ma_period = 7, #in terms of days\r\n",
    "             indicators = False,\r\n",
    "             imfs = False,\r\n",
    "             ohlv = False,\r\n",
    "              **kwargs):\r\n",
    "\r\n",
    "        X, y, dfs = {}, {}, {}     \r\n",
    "        \r\n",
    "        for cur in currency_list:\r\n",
    "            df = pd.read_csv(f\"../data/0_raw/Binance/{str.lower(cur)}_usdt_{data_frequency}.csv\", header=None,index_col=0)\r\n",
    "            df.index = pd.to_datetime(df.index, unit='ms')\r\n",
    "            df.sort_index(inplace=True)\r\n",
    "            df.columns = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\r\n",
    "            \r\n",
    "            if indicators:\r\n",
    "                from ta import add_all_ta_features\r\n",
    "                indicators_df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\r\n",
    "                df[indicators_df.columns] = indicators_df\r\n",
    "          \r\n",
    "            if imfs:\r\n",
    "                from PyEMD import EEMD\r\n",
    "                eemd = EEMD(parallel=True, processes=2)\r\n",
    "                imfs_result = eemd(df[\"close\"].values, max_imf=7)\r\n",
    "                imf_features = [\"imf_\"+str(i) for i in range(imfs_result.shape[0])]\r\n",
    "                df = pd.concat((df, pd.DataFrame(imfs_result.T, columns=imf_features, index=df.index)), axis=1)\r\n",
    "            \r\n",
    "            if log_price:\r\n",
    "                df[[\"close\", \"open\", \"high\", \"low\"]] = df[[\"close\", \"open\", \"high\", \"low\"]].apply(np.log, axis=1)\r\n",
    "                   \r\n",
    "            if num_classes == 3:\r\n",
    "                pct_diff = df['close'].pct_change()\r\n",
    "                quantile_value = pct_diff.abs().quantile(neutral_quantile).loc[neutral_quantile]\r\n",
    "                \r\n",
    "                conditions = [(pct_diff < 0) & (pct_diff.abs() > quantile_value),\r\n",
    "                              (pct_diff > 0) & (pct_diff.abs() > quantile_value)]\r\n",
    "\r\n",
    "                classes = [0,1] # 2 is the default class if none of conditions is met, i.e. price change in the neutral range\r\n",
    "            \r\n",
    "                change_dir = np.select(conditions, classes, default=2)\r\n",
    "            \r\n",
    "            else: \r\n",
    "                change_dir = df['close'].diff().apply(lambda x: 0 if x <= 0 else 1)\r\n",
    "            \r\n",
    "            df.insert(loc=0, column=\"change_dir\", value=change_dir)   \r\n",
    "            \r\n",
    "            if remove_trend:\r\n",
    "                #from statsmodels.tsa.seasonal import seasonal_decompose\r\n",
    "                #ma_period = ma_period if pred_frequency in ['d', 'D'] else ma_period * 4\r\n",
    "                #components = seasonal_decompose(df[\"close\"], model=\"additive\", period = ma_period, two_sided=False)\r\n",
    "                #df[\"close\"] -= components.trend\r\n",
    "                df['diff'] = df['close'].diff()\r\n",
    "                #df['diff'] = df['close'].pct_change()\r\n",
    "                if not decompose:\r\n",
    "                    df.drop('close', axis=1, inplace=True)  \r\n",
    "\r\n",
    "            if decompose: \r\n",
    "                from statsmodels.tsa.seasonal import seasonal_decompose\r\n",
    "                ma_period = ma_period if pred_frequency == '1d' else ma_period * 4 #if pred_frequency is 6h, then multiply the ma_period by 4 \r\n",
    "                components = seasonal_decompose(df[\"close\"], model=\"additive\", period = ma_period, two_sided=False)\r\n",
    "                df['trend'] = components.trend\r\n",
    "                df['residual'] = components.resid  \r\n",
    "                df['seasonal'] = components.seasonal\r\n",
    "\r\n",
    "            if ohlv: #keeping open, high, low, and volume\r\n",
    "                df[['open_d', 'high_d', 'low_d', 'volume_d']] = df[[\"open\", \"high\", \"low\", \"volume\"]].diff() \r\n",
    "            else:\r\n",
    "                df.drop([\"open\", \"high\", \"low\", \"volume\"], axis=1, inplace=True)\r\n",
    "            \r\n",
    "            dfs[cur] = df.dropna()\r\n",
    "        \r\n",
    "        min_dates = [df.index.min() for cur, df in dfs.items()]\r\n",
    "        max_dates = [df.index.max() for cur, df in dfs.items()]\r\n",
    "        beg_date = max([max(min_dates), beg_date])\r\n",
    "        end_date = min([min(max_dates), end_date])\r\n",
    "        common_range = pd.date_range(beg_date, end_date, freq=data_frequency)\r\n",
    "        \r\n",
    "        missing = set()\r\n",
    "        common_set = set(common_range)\r\n",
    "        for cur, df in dfs.items():\r\n",
    "            missing_steps = common_set.difference(df.index)\r\n",
    "            missing |= missing_steps\r\n",
    "        common_range = common_range.drop(missing)\r\n",
    "        \r\n",
    "        X = np.array([dfs[cur].loc[common_range].drop([\"change_dir\"], axis=1).values for cur in currency_list])\r\n",
    "        y = np.array([dfs[cur].loc[common_range, \"change_dir\"].values for cur in currency_list])\r\n",
    "        features = df.columns.tolist()\r\n",
    "        features.remove(\"change_dir\")\r\n",
    "\r\n",
    "        return X, y, features, dfs, common_range"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def get_data2(currency_list,\r\n",
    "             data_frequency,\r\n",
    "             pred_frequency,\r\n",
    "             num_classes,\r\n",
    "             window_size,\r\n",
    "             neutral_quantile = 0.33,\r\n",
    "             beg_date = pd.Timestamp(2017,1,1),\r\n",
    "             end_date = pd.Timestamp.now(),\r\n",
    "             log_price = True,\r\n",
    "             remove_trend = False,\r\n",
    "             ma_period = 0,\r\n",
    "             include_indicators = False,\r\n",
    "             include_imfs = False,\r\n",
    "             ohlv = False,\r\n",
    "             drop_missing = True,\r\n",
    "              **kwargs):\r\n",
    "\r\n",
    "        X, y, dfs = {}, {}, {}     \r\n",
    "        \r\n",
    "        for cur in currency_list:\r\n",
    "            df = pd.read_csv(f\"../data/0_raw/Binance/{str.lower(cur)}_usdt_{data_frequency}.csv\", header=None,index_col=0)\r\n",
    "            df.index = pd.to_datetime(df.index, unit='ms')\r\n",
    "            df.sort_index(inplace=True)\r\n",
    "            df.columns = [\"open\",\"high\",\"low\",\"close\",\"volume\"]\r\n",
    "            \r\n",
    "            if include_indicators:\r\n",
    "                from ta import add_all_ta_features\r\n",
    "                indicators_df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\", fillna=True)\r\n",
    "                df[indicators_df.columns] = indicators_df\r\n",
    "            \r\n",
    "            if include_imfs:\r\n",
    "                from PyEMD import EEMD\r\n",
    "                eemd = EEMD(parallel=True, processes=2)\r\n",
    "                imfs = eemd(df[\"close\"].values, max_imf=7)\r\n",
    "                imf_features = [\"imf_\"+str(i) for i in range(imfs.shape[0])]\r\n",
    "                df = pd.concat((df, pd.DataFrame(imfs.T, columns=imf_features, index=df.index)), axis=1)\r\n",
    "            \r\n",
    "            if log_price:\r\n",
    "                df[[\"close\", \"open\", \"high\", \"low\"]] = df[[\"close\", \"open\", \"high\", \"low\"]].apply(np.log, axis=1)\r\n",
    "                   \r\n",
    "            if num_classes == 3:\r\n",
    "                df['pct_diff'] = df['close'].pct_change()\r\n",
    "                neutral_quantiles = df['pct_diff'].abs().quantile(neutral_quantile).loc[neutral_quantile]\r\n",
    "\r\n",
    "                conditions = [(df['pct_diff'] < 0) & (df['pct_diff'].abs() > neutral_quantiles),\r\n",
    "                              (df['pct_diff'] > 0) & (df['pct_diff'].abs() > neutral_quantiles)]\r\n",
    "\r\n",
    "                classes = [0,1] # 2 is the default class if none of conditions is met, i.e. price change in the neutral range\r\n",
    "            \r\n",
    "                change_dir = np.select(conditions, classes, default=2)\r\n",
    "            \r\n",
    "            else:\r\n",
    "                df['diff'] = df['close'].diff()\r\n",
    "                change_dir = df['diff'].apply(lambda x: 0 if x <= 0 else 1)\r\n",
    "            \r\n",
    "            df.insert(loc=0, column=\"change_dir\", value=change_dir)   \r\n",
    "            df.dropna(inplace=True)  \r\n",
    "            \r\n",
    "            if remove_trend:\r\n",
    "                from statsmodels.tsa.seasonal import seasonal_decompose\r\n",
    "                components = seasonal_decompose(df[\"close\"].values, period=3, model=\"additive\")#, period = ma_period, two_sided=False)\r\n",
    "                df[\"close\"] -= components.trend\r\n",
    "                df.dropna(inplace=True)\r\n",
    "                \r\n",
    "            if not ohlv: #keeping open, high, low, and volume\r\n",
    "                df.drop([\"open\", \"high\", \"low\", \"volume\"], axis=1, inplace=True)\r\n",
    "\r\n",
    "            dfs[cur] = df\r\n",
    "        \r\n",
    "        min_dates = [df.index.min() for cur, df in dfs.items()]\r\n",
    "        max_dates = [df.index.max() for cur, df in dfs.items()]\r\n",
    "        beg_date = max([max(min_dates), beg_date])\r\n",
    "        end_date = min([min(max_dates), end_date])\r\n",
    "        common_range = pd.date_range(beg_date, end_date, freq=data_frequency)\r\n",
    "        \r\n",
    "        missing = set()\r\n",
    "        common_set = set(common_range)\r\n",
    "        for cur, df in dfs.items():\r\n",
    "            missing_steps = common_set.difference(df.index)\r\n",
    "            missing |= missing_steps\r\n",
    "        common_range = common_range.drop(missing)\r\n",
    "        \r\n",
    "        diff_col = 'pct_diff' if num_classes == 3 else 'diff'\r\n",
    "\r\n",
    "        X = np.array([dfs[cur].loc[common_range].drop([\"change_dir\", diff_col], axis=1).values for cur in currency_list])\r\n",
    "        y = np.array([dfs[cur].loc[common_range, \"change_dir\"].values for cur in currency_list])\r\n",
    "        features = df.columns.tolist()\r\n",
    "        features.remove(\"change_dir\")\r\n",
    "        \r\n",
    "        return X, y, features, dfs, common_range"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "CURRENCY_LST = ['BTC', 'ETH', 'LTC', 'XRP', 'ADA']\r\n",
    "num_classes = 2\r\n",
    "DATA_FREQ = '1d'\r\n",
    "PRED_FREQ = '1d'\r\n",
    "WINDOW_SIZE = 400\r\n",
    "NEUTRAL_QUANTILE = 0.33,\r\n",
    "dataset_percentages = [0.90, 0.0, 0.1]\r\n",
    "train_pct = 0.9\r\n",
    "LOOK_AHEAD = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "X, y, features, dfs, common_range = get_data(currency_list= CURRENCY_LST,\r\n",
    "                               data_frequency=DATA_FREQ,\r\n",
    "                               pred_frequency=PRED_FREQ,\r\n",
    "                               num_classes = num_classes, \r\n",
    "                               window_size = WINDOW_SIZE,\r\n",
    "                               neutral_quantile = NEUTRAL_QUANTILE,\r\n",
    "                               log_price = True,\r\n",
    "                               remove_trend = True,\r\n",
    "                               ma_period = 7,\r\n",
    "                               indicators = False,\r\n",
    "                               imfs = False,\r\n",
    "                               decompose = False,\r\n",
    "                               ohlv = False,\r\n",
    "                               beg_date = pd.Timestamp(2017,1,1),\r\n",
    "                               end_date = pd.Timestamp(2022,1,1))\r\n",
    "\r\n",
    "train_dataset, val_dataset, test_dataset = [TimeSeriesDataset(X, y, dtype, CURRENCY_LST, dataset_percentages, WINDOW_SIZE, DATA_FREQ, PRED_FREQ) for dtype in ['train', 'val', 'test']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "X.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(5, 1197, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df = dfs['BTC']\r\n",
    "df.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>change_dir</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.530822</td>\n",
       "      <td>0.001648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499220</td>\n",
       "      <td>0.043587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.502607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.015750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.019939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        change_dir         diff\n",
       "count  1460.000000  1460.000000\n",
       "mean      0.530822     0.001648\n",
       "std       0.499220     0.043587\n",
       "min       0.000000    -0.502607\n",
       "25%       0.000000    -0.015750\n",
       "50%       1.000000     0.001810\n",
       "75%       1.000000     0.019939\n",
       "max       1.000000     0.202952"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def rolling_window(a, window):\r\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\r\n",
    "    strides = a.strides + (a.strides[-1],)\r\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\r\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\r\n",
    "from xgboost import XGBClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "LOOK_AHEAD=6\r\n",
    "data = {}\r\n",
    "for i, cur in enumerate(CURRENCY_LST):\r\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\r\n",
    "    \r\n",
    "    train_size = int(len(seq_X) * train_pct)\r\n",
    "    test_size = len(seq_X) - train_size\r\n",
    "\r\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\r\n",
    "    X_train = seq_X[:train_size]\r\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\r\n",
    "    scaler = StandardScaler()\r\n",
    "    X_train = scaler.fit_transform(X_train)\r\n",
    "    X_test = scaler.transform(X_test)\r\n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\r\n",
    "    y_test = y[i][train_size:]\r\n",
    "    lr = LogisticRegression()\r\n",
    "    lr.fit(X_train[:-LOOK_AHEAD], y_train[LOOK_AHEAD:])\r\n",
    "    print(cur)\r\n",
    "    #print(lr.coef_)\r\n",
    "    print(lr.score(X_train[:-LOOK_AHEAD], y_train[LOOK_AHEAD:]))\r\n",
    "    print(lr.score(X_test[:-LOOK_AHEAD], y_test[LOOK_AHEAD:]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BTC\n",
      "0.9353023909985936\n",
      "0.8734177215189873\n",
      "ETH\n",
      "0.9563994374120957\n",
      "0.8881856540084389\n",
      "LTC\n",
      "0.929676511954993\n",
      "0.8586497890295358\n",
      "XRP\n",
      "0.8987341772151899\n",
      "0.8396624472573839\n",
      "ADA\n",
      "0.9240506329113924\n",
      "0.8502109704641351\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "data = {}\r\n",
    "for i, cur in enumerate(CURRENCY_LST):\r\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\r\n",
    "\r\n",
    "    train_size = int(len(seq_X) * train_pct)\r\n",
    "    test_size = len(seq_X) - train_size\r\n",
    "\r\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\r\n",
    "    X_train = seq_X[:train_size]\r\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\r\n",
    "    scaler = StandardScaler()\r\n",
    "    X_train = scaler.fit_transform(X_train)\r\n",
    "    X_test = scaler.transform(X_test)\r\n",
    "    \r\n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\r\n",
    "    y_test = y[i][train_size:]\r\n",
    "    lr = LogisticRegression(max_iter=1000)\r\n",
    "    lr.fit(X_train, y_train)\r\n",
    "    print(cur)\r\n",
    "    #print(lr.coef_)\r\n",
    "    print(lr.score(X_train, y_train))\r\n",
    "    print(lr.score(X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BTC\n",
      "0.9274755927475593\n",
      "0.8770833333333333\n",
      "ETH\n",
      "0.9567642956764296\n",
      "0.8916666666666667\n",
      "LTC\n",
      "0.9400278940027894\n",
      "0.8541666666666666\n",
      "XRP\n",
      "0.9316596931659693\n",
      "0.8645833333333334\n",
      "ADA\n",
      "0.9567642956764296\n",
      "0.88125\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "data = {}\r\n",
    "for i, cur in enumerate(CURRENCY_LST):\r\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\r\n",
    "    \r\n",
    "    train_size = int(len(seq_X) * train_pct)\r\n",
    "    test_size = len(seq_X) - train_size\r\n",
    "\r\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\r\n",
    "    X_train = seq_X[:train_size]\r\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\r\n",
    "    \r\n",
    "    scaler = StandardScaler()\r\n",
    "    X_train = scaler.fit_transform(X_train)\r\n",
    "    X_test = scaler.transform(X_test)\r\n",
    "    \r\n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\r\n",
    "    y_test = y[i][train_size:]\r\n",
    "    rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', n_jobs=-1)\r\n",
    "    rf.fit(X_train, y_train)\r\n",
    "    print(cur)\r\n",
    "    print(rf.score(X_train, y_train))\r\n",
    "    print(rf.score(X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BTC\n",
      "1.0\n",
      "0.9166666666666666\n",
      "ETH\n",
      "1.0\n",
      "0.9354166666666667\n",
      "LTC\n",
      "1.0\n",
      "0.9104166666666667\n",
      "XRP\n",
      "1.0\n",
      "0.9104166666666667\n",
      "ADA\n",
      "1.0\n",
      "0.9166666666666666\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "pd.DataFrame(rf.feature_importances_).hist()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'0'}>]], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "np.argmax(rf.feature_importances_)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "399"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "data = {}\r\n",
    "for i, cur in enumerate(CURRENCY_LST):\r\n",
    "    seq_X = rolling_window(X[i].squeeze(), WINDOW_SIZE)[:-1]\r\n",
    "    \r\n",
    "    train_size = int(len(seq_X) * train_pct)\r\n",
    "    test_size = len(seq_X) - train_size\r\n",
    "\r\n",
    "    data[cur] = pd.DataFrame(np.hstack((seq_X, y[i][WINDOW_SIZE:].reshape(-1,1))))\r\n",
    "    X_train = seq_X[:train_size]\r\n",
    "    X_test = seq_X[train_size-WINDOW_SIZE:]\r\n",
    "    \r\n",
    "    scaler = StandardScaler()\r\n",
    "    X_train = scaler.fit_transform(X_train)\r\n",
    "    X_test = scaler.transform(X_test)\r\n",
    "    \r\n",
    "    y_train = y[i][WINDOW_SIZE:train_size+WINDOW_SIZE]\r\n",
    "    y_test = y[i][train_size:]\r\n",
    "    xgb = XGBClassifier(n_estimators=100, use_label_encoder=False, eval_metric='logloss', n_jobs=-1)\r\n",
    "    xgb.fit(X_train, y_train)\r\n",
    "    print(cur)\r\n",
    "    print(xgb.score(X_train, y_train))\r\n",
    "    print(xgb.score(X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BTC\n",
      "1.0\n",
      "0.9125\n",
      "ETH\n",
      "1.0\n",
      "0.91875\n",
      "LTC\n",
      "1.0\n",
      "0.9166666666666666\n",
      "XRP\n",
      "1.0\n",
      "0.9208333333333333\n",
      "ADA\n",
      "1.0\n",
      "0.9083333333333333\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "#!pip install -U numpy==1.18 --user #required if keras produces an error related to numpy"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: numpy==1.18 in c:\\users\\furkan\\appdata\\roaming\\python\\python38\\site-packages (1.18.0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "from keras.models import Sequential\r\n",
    "from keras.layers import LSTM\r\n",
    "from keras.layers import Dense, Bidirectional"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "batch_size = 16\r\n",
    "# define model\r\n",
    "model = Sequential()\r\n",
    "model.add(Bidirectional(LSTM(50, activation='relu', input_shape=(WINDOW_SIZE, 1))))\r\n",
    "#model.add(Bidirectional(LSTM(100, activation='relu', input_shape=(200,WINDOW_SIZE, 1))))\r\n",
    "model.add(Dense(1, activation='sigmoid'))\r\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['acc'])\r\n",
    "# fit model\r\n",
    "model.fit(X_train.reshape(X_train.shape[0],-1,1), \r\n",
    "          y_train, \r\n",
    "          epochs=30, \r\n",
    "          batch_size=batch_size, \r\n",
    "          verbose=2,\r\n",
    "         validation_data=(X_test.reshape(X_test.shape[0],-1,1), y_test))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "X_train.reshape(X_train.shape[0],-1,1).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(717, 400, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "batch_size = 8\r\n",
    "model = Sequential()\r\n",
    "model.add(Dense(100, activation='relu'))\r\n",
    "model.add(Dense(1, activation='sigmoid'))\r\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\r\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=batch_size, verbose=2, validation_data=(X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "90/90 - 2s - loss: 0.8139 - acc: 0.4937 - val_loss: 0.4028 - val_acc: 0.8583\n",
      "Epoch 2/20\n",
      "90/90 - 0s - loss: 0.3647 - acc: 0.8842 - val_loss: 0.2854 - val_acc: 0.9333\n",
      "Epoch 3/20\n",
      "90/90 - 0s - loss: 0.2191 - acc: 0.9833 - val_loss: 0.2333 - val_acc: 0.9312\n",
      "Epoch 4/20\n",
      "90/90 - 0s - loss: 0.1297 - acc: 0.9986 - val_loss: 0.2125 - val_acc: 0.9271\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cf5a346d587ec1341992060547c85a6411ea706a55887781b800d60fda342a75"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}